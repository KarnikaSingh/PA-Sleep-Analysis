{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "\n",
    "from glob import iglob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = filepath\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for f in iglob(path, recursive=True)), ignore_index=True)\n",
    "\n",
    "# Get MMI data\n",
    "df_mmi = df[df['Type'] == 'meanMotionIntensity']\n",
    "\n",
    "df_mmi['Start Time'] = df_mmi['Start Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_mmi['End Time'] = df_mmi['End Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_mmi['Start_Time_Offset'] = df_mmi['Start Time'] + pd.to_timedelta(df_mmi['Time Zone Offset'], unit='s')\n",
    "df_mmi['End_Time_Offset'] = df_mmi['End Time'] + pd.to_timedelta(df_mmi['Time Zone Offset'], unit='s')\n",
    "\n",
    "# get steps data\n",
    "df_steps = df[df['Type'] == 'steps']\n",
    "df_steps['User UUID'].unique()\n",
    "\n",
    "df_steps['Start Time'] = df_steps['Start Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_steps['End Time'] = df_steps['End Time'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps['Start_Time_Offset'] = df_steps['Start Time'] + pd.to_timedelta(df_steps['Time Zone Offset'], unit='s')\n",
    "df_steps['End_Time_Offset'] = df_steps['End Time'] + pd.to_timedelta(df_steps['Time Zone Offset'], unit='s')\n",
    "\n",
    "# df['Start_Time_Offset'] = df.loc[:,['Start Time','Time Zone Offset']].sum(axis=1)\n",
    "\n",
    "df_merge_steps_mi = pd.merge(df_steps, df_mmi, left_on=['User UUID', 'Start_Time_Offset', 'End_Time_Offset'], right_on=['User UUID', 'Start_Time_Offset', 'End_Time_Offset'])\n",
    "df_merge_steps_mi['User UUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merge_steps_mi)\n",
    "\n",
    "df_merge_steps_mi\n",
    "\n",
    "df_merge_steps_mi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove value_y from duplicate subset\n",
    "df_merge_dup = df_merge_steps_mi.drop_duplicates(subset=['User UUID', 'Start_Time_Offset', 'End_Time_Offset', 'Value_x'], keep='first')\n",
    "df_merge_dup\n",
    "\n",
    "sixtyone_epoch = df_merge_dup[df_merge_dup['User UUID']=='u-22Kw0lWnvI27MXMuRggpVA']\n",
    "sixtyone_epoch = sixtyone_epoch[sixtyone_epoch['Start Time_x'] == '2021-02-28T15:45:00Z']\n",
    "sixtyone_epoch[['User UUID', 'End Time_x', 'End Time_y', 'Value_y', 'Value_x']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_dup['End Time'] = df_merge_dup['End Time_x'].apply(pd.to_datetime)\n",
    "\n",
    "df_merge_dup['Start_Time_Date_Offset_x'] = df_merge_dup['Start Time Offset'].dt.date\n",
    "df_merge_dup['End_Time_Date_Offset_x'] = df_merge_dup['End Time Offset'].dt.date\n",
    "\n",
    "df_merge_dup['month_year'] = df_merge_dup['Start Time Offset'].dt.to_period('M')\n",
    "\n",
    "# df_merge_dup['Total_Steps_Per_Day'] = df_merge_dup.groupby(['Start_Time_Date_Offset_x', 'User UUID'])['Value_x'].transform(sum())\n",
    "\n",
    "df_merge_dup['Total_Steps_Per_Day_pre_missing'] = df_merge_dup.groupby(['Start_Time_Date_Offset_x', 'User UUID'])['Value_x'].transform('sum')\n",
    "\n",
    "# df_merge_steps_mi_dup_z_nz_2['Average_Monthly_Steps_pre_missing'] = df_merge_steps_mi_dup_z_nz_2.groupby([' User UUID', 'month_year'])['Total_Steps_Per_Day'].transform('mean')\n",
    "\n",
    "df_merge_dup['Mon_Year'] = df_merge_dup['Start_Time_Offset'].dt.strftime('%b-%Y')\n",
    "\n",
    "df_merge_dup['Month_Year_Name'] = df_merge_dup['Mon_Year']\n",
    "\n",
    "df_merge_dup.loc[(df_merge_dup['Start_Time_Date_Offset_x'] == dt.date(2020, 3, 15)), 'Month_Year_Name'] = '1-14 Mar-2020'\n",
    "df_merge_dup.loc[(df_merge_dup['Start_Time_Date_Offset_x'] > dt.date(2020, 3, 15)) & (df_merge_dup['Start_Time_Date_Offset_x'] <= dt.date(2020, 3, 31)), 'Month_Year_Name'] = '15-31 Mar-2020'\n",
    "df_merge_dup.loc[(df_merge_dup['Start_Time_Date_Offset_x'] == dt.date(2020, 4, 1)), 'Month_Year_Name'] = df_merge_dup.Month_Year_Name\n",
    "\n",
    "df_merge_dup['Average_Monthly_Steps_Lockdown_pre_missing'] = df_merge_dup.groupby(['User UUID', 'Month_Year_Name'])['Total_Steps_Per_Day_pre_missing'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero = df_merge_dup[df_merge_dup['Value_y'] < 1]\n",
    "df_zero['Value_y'].unique()\n",
    "\n",
    "df_non_zero = df_merge_dup[df_merge_dup['Value_y'] > 1]\n",
    "df_non_zero\n",
    "df_non_zero['User UUID'].unique()\n",
    "\n",
    "# Calculate missingness\n",
    "# df_steps_missing = df_merge_steps_mi_dup_non_zero\n",
    "df_steps_missing = df_non_zero\n",
    "\n",
    "df_steps_missing['Num_of_days'] = 0\n",
    "df_steps_missing['total_percent_missing'] = 0\n",
    "df_steps_missing['percent_missing_per_day'] = 0\n",
    "df_steps_missing['Epochs_per_day'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_steps_missing['Valid Day'] = 'no'\n",
    "df_steps_missing.loc[(df_steps_missing['Epochs_per_day'] > 40), 'Valid Day'] = 'yes'\n",
    "\n",
    "# df_steps_missing_Lockdown_all_years_copy = df_steps_missing\n",
    "\n",
    "# restrict time\n",
    "df_all_periods = df_steps_missing[(df_steps_missing['Start_Time_Date_Offset_x'] > dt.date(2019, 3, 1)) & (df_steps_missing['Start_Time_Date_Offset_x'] < dt.date(2021, 6, 30))]\n",
    "\n",
    "print(df_all_periods['Start_Time_Date_Offset_x'].min())\n",
    "print(df_all_periods['Start_Time_Date_Offset_x'].max())\n",
    "\n",
    "df_all_periods.loc[(df_all_periods['Start_Time_Date_Offset_x'] < dt.date(2020, 3, 15)) & (df_all_periods['Start_Time_Date_Offset_x'] > dt.date(2019, 3, 1)), 'closure_status'] = 'Pre Closure'\n",
    "df_all_periods.loc[(df_all_periods['Start_Time_Date_Offset_x'] < dt.date(2021, 3, 31)) & (df_all_periods['Start_Time_Date_Offset_x'] > dt.date(2020, 3, 15)), 'closure_status'] = 'During Closure'\n",
    "df_all_periods.loc[(df_all_periods['Start_Time_Date_Offset_x'] > dt.date(2021, 3, 31)), 'closure_status'] = 'Post Closure'\n",
    "\n",
    "print(df_all_periods.groupby('closure_status')['Start_Time_Date_Offset_x'].min())\n",
    "print(df_all_periods.groupby('closure_status')['Start_Time_Date_Offset_x'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_days = df_all_periods[df_all_periods['Valid Day'] == 'yes']\n",
    "\n",
    "df_valid_days['Num_of_days_valid_epochs'] = df_valid_days.groupby(['User UUID'])['Start_Time_Date_Offset_x'].transform('nunique')\n",
    "\n",
    "df_valid_days_daycount = df_valid_days[df_valid_days['Num_of_days_valid_epochs'] > 60]\n",
    "\n",
    "df_valid_days_daycount['Epochs_per_day'].min()\n",
    "df_valid_days_daycount['Epochs_per_day'].max()\n",
    "\n",
    "epoch_count = df_all_periods\n",
    "epoch_count['Num_of_days_valid_epochs'] = epoch_count.groupby(['User UUID'])['Start_Time_Date_Offset_x'].transform('nunique')\n",
    "\n",
    "epoch_count = df_all_periods.drop_duplicates(subset=['User UUID', 'Num_of_days_valid_epochs'], keep='first')\n",
    "\n",
    "\n",
    "print(range(len(epoch_count_only)))\n",
    "print(194/2)\n",
    "\n",
    "epoch_count_only.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(100,40))\n",
    "plt.figure(figsize=(60,20))\n",
    "sns.set(font_scale=5)\n",
    "default_x_ticks = range(len(epoch_count_only))\n",
    "fig, ax = plt.subplots(figsize=(60,20))\n",
    "ax.hist(epoch_count_only['Num_of_days_valid_epochs'], bins=61, cumulative=-1, density=False)\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 120]['User UUID'].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 61].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 40].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 70].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 80].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 90].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "df_epoch_dup = df_all_periods.drop_duplicates(subset=['User UUID', 'Start_Time_Date_Offset_x'], keep='last', inplace=False)\n",
    "df2 = df_epoch_dup.groupby(['User UUID', 'Epochs_per_day'])['Start_Time_Date_Offset_x'].count()\n",
    "\n",
    "df3 = df2.reset_index()\n",
    "\n",
    "df3['Epochs_per_day'] = df3['Epochs_per_day'].replace(np.nan, 0)\n",
    "df3['Start_Time_Date_Offset_x'] = df3['Start_Time_Date_Offset_x'].replace(np.nan, 0)\n",
    "\n",
    "df_pivot = df3.pivot_table(values='User UUID', index=['Epochs_per_day'], columns=['Start_Time_Date_Offset_x'], aggfunc=pd.Series.nunique)\n",
    "df_pivot.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20, 7)})\n",
    "sns.set_context(\"paper\", rc={\"font.size\":90,\"axes.titlesize\":50,\"axes.labelsize\":20})\n",
    "sns.set(rc={\"axes.facecolor\":\"snow\", \"figure.facecolor\":\"white\"})\n",
    "ax = sns.heatmap(df_pivot, cmap=\"rocket_r\", mask=(df_pivot==0))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "df_valid_days_daycount['User UUID'].nunique()\n",
    "\n",
    "df_valid_days_daycount['Total_Steps_Per_Day_post_missing'] = df_valid_days_daycount.groupby(['Start_Time_Date_Offset_x', 'User UUID'])['Total_Steps_Per_Day'].transform('sum')\n",
    "\n",
    "df_valid_days_daycount['Average_Monthly_Steps_Lockdown_post_missing'] = df_valid_days_daycount.groupby(['User UUID', 'Month_Year_Name'])['Total_Steps_Per_Day_post_missing'].transform('mean')\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_days_daycount_dup = df_valid_days_daycount.drop_duplicates(subset=['User UUID', 'Average_Monthly_Steps_Lockdown_post_missing', 'Month_Year_Name'], keep='first')\n",
    "df_valid_days_daycount_dup\n",
    "\n",
    "# Min\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].min()\n",
    "\n",
    "# Max\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].max()\n",
    "\n",
    "# Mean\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].mean()\n",
    "\n",
    "# Std\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].std()\n",
    "\n",
    "# Users\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['User UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_days_daycount_dup_month = df_valid_days_daycount_dup\n",
    "df_valid_days_daycount_dup_month['average_steps_per_month_post_missing'] = df_valid_days_daycount_dup_month.groupby(['Month_Year_Name'])['Average_Monthly_Steps_Lockdown_post_missing'].transform('mean')\n",
    "df_valid_days_daycount_dup_month = df_valid_days_daycount_dup_month.drop_duplicates(subset=['average_steps_per_month_post_missing', 'Month_Year_Name'], keep='first')\n",
    "df_valid_days_daycount_dup_month\n",
    "\n",
    "df_valid_days_daycount_dup_month['Month_Year_Name'].unique()\n",
    "\n",
    "# Min\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].min()\n",
    "\n",
    "# Max\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].max()\n",
    "\n",
    "# Mean\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].mean()\n",
    "\n",
    "# Std\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].std()\n",
    "\n",
    "# Users\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['User UUID'].nunique()\n",
    "\n",
    "# Exclude summer for TOD comparison with overall\n",
    "df_valid_days_daycount_dup_month_non_sum = df_valid_days_daycount_dup_month[(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jun-2020') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jul-2020') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Aug-2020') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jun-2019') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jul-2019') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Aug-2019') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jun-2021') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jul-2021') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Aug-2021')]\n",
    "df_valid_days_daycount_dup_month_non_sum\n",
    "\n",
    "# Mean\n",
    "df_valid_days_daycount_dup_month_non_sum.groupby('closure_status')['average_steps_per_month_post_missing'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "# df_steps_missing_Lockdown_all_years_valid_days_daycount_fig4['year_only'] = df_steps_missing_Lockdown_all_years_valid_days_daycount\n",
    "\n",
    "df_valid_days_daycount_dup_fig = df_valid_days_daycount_dup\n",
    "df_valid_days_daycount_dup_fig['pre_avg'] = 8809.83\n",
    "\n",
    "plt.figure(figsize=(60, 20))\n",
    "sns.set(font_scale=5)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"Set1\", 8, .75)\n",
    "ax = sns.lineplot(x='Month_Year_Name', y='Average_Monthly_Steps_Lockdown_post_missing', \n",
    "                  data=df_valid_days_daycount_dup_fig, color='darkcyan', \n",
    "                  linewidth=15, sort=False)\n",
    "sns.lineplot(x='Month_Year_Name', y='pre_avg', \n",
    "             data=df_valid_days_daycount_dup_fig, color='grey', \n",
    "             linestyle='--', linewidth=10, sort=False)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel(\"Month\", fontdict={'fontsize': 60, 'fontweight': 'bold'}, labelpad=-2)\n",
    "ax.set_ylabel(\"Average Daily Number of Steps Per Month\", fontdict={'fontsize': 55, 'fontweight': 'bold'})\n",
    "ax.set_title(\"Average Daily Step Values for Participants (Non zero MMI, after missingness analysis)\", fontdict={'fontsize': 60, 'fontweight': 'bold'})\n",
    "ax.axvline(\"1-14 Mar-2020\", color=\"firebrick\", linestyle=\"--\", lw=10)\n",
    "ax.legend(loc=\"upper right\", frameon=True, fontsize=50)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='50') # for Legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='50') # for Legend title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "steps_pre_closure = df_valid_days_daycount_dup[df_valid_days_daycount_dup['closure_status'] == 'Pre Closure']\n",
    "\n",
    "steps_pre_closure['Monthly_Avg'] = steps_pre_closure.groupby(['Month_Year_Name'])['Average_Monthly_Steps_Lockdown_post_missing'].transform('mean')\n",
    "\n",
    "steps_pre_closure['month_num'] = steps_pre_closure['Start_Time_Offset'].dt.month\n",
    "# steps_pre['month_num'].unique()\n",
    "steps_pre_closure = steps_pre_closure.sort_values(by=['month_num'])\n",
    "# steps_pre_closure\n",
    "\n",
    "steps_pre_closure_col = steps_pre_closure[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_pre_closure_dup = steps_pre_closure_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "# steps_pre_closure_dup\n",
    "\n",
    "steps_dur_closure = df_valid_days_daycount_dup[df_valid_days_daycount_dup['closure_status'] == 'During Closure']\n",
    "\n",
    "steps_dur_closure['Monthly_Avg'] = steps_dur_closure.groupby(['Month_Year_Name'])['Average_Monthly_Steps_Lockdown_post_missing'].transform('mean')\n",
    "\n",
    "steps_dur_closure['month_num'] = steps_dur_closure['Start_Time_Offset'].dt.month\n",
    "# steps_pre['month_num'].unique()\n",
    "steps_dur_closure = steps_dur_closure.sort_values(by=['month_num'])\n",
    "# steps_dur_closure\n",
    "\n",
    "steps_dur_closure_col = steps_dur_closure[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_dur_closure_dup = steps_dur_closure_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "# steps_dur_closure_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "U1, p = mannwhitneyu(steps_dur_closure_dup['Monthly_Avg'], steps_pre_closure_dup['Monthly_Avg'])\n",
    "print(U1)\n",
    "print(p)\n",
    "print(p * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time of day analysis\n",
    "df_closure_tod = df_valid_days_daycount\n",
    "\n",
    "df_closure_tod['Start Time Only Time'] = df_closure_tod['Start_Time_Offset'].dt.strftime(\"%H:%M:%S\")\n",
    "# all_data_merged_steps[all_data_merged_steps['Start Time Only Time'] > '16:15:00']\n",
    "# base on data instead\n",
    "df_closure_tod['Time_Of_Day'] = \"Night\"\n",
    "df_closure_tod.loc[df_closure_tod['Start Time Only Time'] < '11:00:00', 'Time_Of_Day'] = 'Morning'\n",
    "df_closure_tod.loc[(df_closure_tod['Start Time Only Time'] >= '07:00:00') &\n",
    "                   (df_closure_tod['Start Time Only Time'] < '16:00:00'), 'Time_Of_Day'] = 'Afternoon'\n",
    "df_closure_tod.loc[(df_closure_tod['Start Time Only Time'] >= '11:00:00') &\n",
    "                   (df_closure_tod['Start Time Only Time'] < '20:00:00'), 'Time_Of_Day'] = 'Evening'\n",
    "\n",
    "# aft = df_steps_missing_all_dates_copy_fig3[df_steps_missing_all_dates_copy_fig3['Time_Of_Day'] == 'Evening']\n",
    "# aft['Start Time Only Time'].unique()\n",
    "\n",
    "df_closure_tod['wkday_Num'] = df_closure_tod['Start_Time_Offset'].dt.weekday\n",
    "df_closure_tod['wkday_Num'].unique()\n",
    "\n",
    "df_closure_tod_wkday = df_closure_tod[df_closure_tod['wkday_Num'].isin([0,1,2,3,4])]\n",
    "df_closure_tod_wkday['wkday_Num'].unique()\n",
    "\n",
    "df_closure_tod_wkday[['wkday_Num', 'Start_Time_Offset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_closure_tod_wkday_school = df_closure_tod_wkday[df_closure_tod_wkday['Time_Of_Day'].isin(['Morning', 'Afternoon'])]\n",
    "df_closure_tod_wkday_school_non_sum = df_closure_tod_wkday_school[~df_closure_tod_wkday_school['Mon_Year'].isin(['Jun-2020', 'Jul-2020', 'Aug-2020', 'Jun-2019', 'Jul-2019', 'Aug-2019', 'Jun-2021', 'Jul-2021', 'Aug-2021'])]\n",
    "df_closure_tod_wkday_school_non_sum['Daily_Sum_TOD'] = df_closure_tod_wkday_school_non_sum.groupby(['Start_Time_Date_Offset_x', 'User_UUID'])['Steps'].transform('sum')\n",
    "df_closure_tod_wkday_school_non_sum['mean_monthly_steps_school'] = df_closure_tod_wkday_school_non_sum.groupby(['User_UUID', 'Month_Year_Name'])['Daily_Sum_TOD'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_non_sum_dup = df_closure_tod_wkday_school_non_sum.drop_duplicates(subset=['User_UUID', 'mean_monthly_steps_school'])\n",
    "df_closure_tod_wkday_school_non_sum_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['mean_monthly_steps_school'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['mean_monthly_steps_school'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['mean_monthly_steps_school'].std()\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_fig = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] != 'Post Closure']\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\n",
    "    \"Pre Closure\": \"mediumpurple\",\n",
    "    \"During Closure\": \"lightcoral\"\n",
    "#     \"#2020\": \"salmon\"\n",
    "}\n",
    "\n",
    "ax = sns.boxplot(x=\"Month_Year_Name\", y=\"mean_monthly_steps_school\", palette=palette, hue=\"closure_status\",\n",
    "                 data=df_closure_tod_fig, linewidth=14,\n",
    "                 showfliers=False, dodge=False, width=0.5,\n",
    "                 showmeans=True)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "# ax.set_title('Average Step Values for Participants Before and After Lockdown For School Times')\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times',\n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_fig = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] != 'Post Closure']\n",
    "fig_2_df_closure_tod = df_closure_tod_fig\n",
    "# Following lines are not completely visible in the image, but here's the visible part:\n",
    "fig_2_df_closure_tod['Month Year Name_Closure'] = fig_2_df_closure_tod['Month Year Name'].str[0:3]\n",
    "fig_2_df_closure_tod.loc[(fig_2_df_closure_tod['Month Year Name_Closure'] == 'Mar'), 'Month Year Name_Closure'] = 'Mar-2020'\n",
    "fig_2_df_closure_tod.loc[(fig_2_df_closure_tod['Month Year Name_Closure'] == 'Mar'), 'Month Year Name_Closure'] = 'Mar-'\n",
    "fig_2_df_closure_tod['month only'] = pd.Categorical(fig_2_df_closure_tod['Month Year Name_Closure'],\n",
    "                                                    categories=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Sep', 'Oct', 'Nov', 'Dec'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out line\n",
    "# df_closure_tod_fig=df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status']=='Post Closure']\n",
    "\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\"Pre Closure\": \"mediumpurple\",\n",
    "           \"During Closure\": \"lightcoral\",\n",
    "           \"#2020\": \"salmon\"}\n",
    "\n",
    "ax = sns.boxplot(x=\"month_only\", y=\"mean_monthly_steps_school\", palette=palette, hue=\"closure_status\",\n",
    "                 data=fig_2_df_closure_tod, linewidth=14, showfliers=False, dodge=False, width=0.5, showmeans=True)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times', \n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one value per month\n",
    "df_closure_tod_wkday_school_non_sum_dup_month = df_closure_tod_wkday_school_non_sum_dup\n",
    "df_closure_tod_wkday_school_non_sum_dup_month['mean_monthly_steps_school_per_month'] = df_closure_tod_wkday_school_non_sum_dup_month.groupby(['Month_Year_Name'])['mean_monthly_steps_school'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup = df_closure_tod_wkday_school_non_sum_dup_month.drop_duplicates(subset=['mean_monthly_steps_school_per_month', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "# Min\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].min()\n",
    "\n",
    "# Max\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].std()\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "steps_pre_closure_wkday_school_non_sum = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] == 'Pre Closure']\n",
    "steps_pre_closure_wkday_school_non_sum['Monthly_Avg'] = steps_pre_closure_wkday_school_non_sum.groupby(['Month_Year_Name'])['mean_monthly_steps_school'].transform('mean')\n",
    "steps_pre_closure_wkday_school_non_sum['month_num'] = steps_pre_closure_wkday_school_non_sum['Start_Time_Offset'].dt.month\n",
    "steps_pre_closure_wkday_school_non_sum = steps_pre_closure_wkday_school_non_sum.sort_values(by=['month_num'])\n",
    "steps_pre_closure_wkday_school_non_sum_col = steps_pre_closure_wkday_school_non_sum[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_pre_closure_wkday_school_non_sum_col_dup = steps_pre_closure_wkday_school_non_sum_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "steps_dur_closure_wkday_school_non_sum = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] == 'During Closure']\n",
    "steps_dur_closure_wkday_school_non_sum['Monthly_Avg'] = steps_dur_closure_wkday_school_non_sum.groupby(['Month_Year_Name'])['mean_monthly_steps_school'].transform('mean')\n",
    "steps_dur_closure_wkday_school_non_sum['month_num'] = steps_dur_closure_wkday_school_non_sum['Start_Time_Offset'].dt.month\n",
    "steps_dur_closure_wkday_school_non_sum = steps_dur_closure_wkday_school_non_sum.sort_values(by=['month_num'])\n",
    "steps_dur_closure_wkday_school_non_sum_col = steps_dur_closure_wkday_school_non_sum[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_dur_closure_wkday_school_non_sum_col_dup = steps_dur_closure_wkday_school_non_sum_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "U1, p = mannwhitneyu(steps_dur_closure_wkday_school_non_sum_col_dup['Monthly_Avg'], steps_pre_closure_wkday_school_non_sum_col_dup['Monthly_Avg'])\n",
    "print(U1)\n",
    "print(p*100)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer months weekday steps analysis (pre-, during-, and post-closure)\n",
    "\n",
    "# Starting dataset used: df_closure_tod_wkday_school\n",
    "df_closure_tod_wkday_school_only_sum = df_closure_tod_wkday_school[\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jun-2020') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jul-2020') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Aug-2020') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jun-2019') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jul-2019') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Aug-2019') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jun-2021') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jul-2021') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Aug-2021')\n",
    "]\n",
    "\n",
    "df_closure_tod_wkday_school_only_sum['Daily_Sum_TOD'] = df_closure_tod_wkday_school_only_sum.groupby(['Start_Time_Date_Offset_x'])['Steps'].transform('sum')\n",
    "df_closure_tod_wkday_school_only_sum['mean_monthly_steps_school_sum'] = df_closure_tod_wkday_school_only_sum.groupby(['User_UUID'])['Daily_Sum_TOD'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_only_sum_dup = df_closure_tod_wkday_school_only_sum.drop_duplicates(subset=['User_UUID', 'mean_monthly_steps_school_sum'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].min()\n",
    "\n",
    "# Max\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].std()\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_wkday_school_only_sum_dup_fig = df_closure_tod_wkday_school_only_sum_dup[df_closure_tod_wkday_school_only_sum_dup['closure_status'] != 'Post Closure']\n",
    "\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\"Pre Closure\": \"yellowgreen\",\n",
    "           \"During Closure\": \"lightsalmon\"\n",
    "#            \"#2020\": \"salmon\"\n",
    "          }\n",
    "\n",
    "ax = sns.boxplot(x=\"month_only\", y=\"mean_monthly_steps_school_sum\", palette=palette, hue='closure_status',\n",
    "                 data=fig_3_df_closure_tod, linewidth=14, showfliers=False,\n",
    "                 showmeans=False, width=0.5)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times',\n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_wkday_school_only_sum_dup_fig = df_closure_tod_wkday_school_only_sum_dup[\n",
    "    df_closure_tod_wkday_school_only_sum_dup['closure_status'] != 'Post Closure']\n",
    "\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\n",
    "    \"Pre Closure\": \"yellowgreen\",\n",
    "    \"During Closure\": \"lightsalmon\"\n",
    "#     \"#2020\": \"salmon\"\n",
    "}\n",
    "\n",
    "ax = sns.boxplot(x=\"month_only\", y=\"mean_monthly_steps_school_sum\", palette=palette, hue=\"closure_status\",\n",
    "                 data=fig_3_df_closure_tod, linewidth=14, showfliers=False,\n",
    "                 showmeans=False, width=0.5)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times',\n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one value per month\n",
    "df_closure_tod_wkday_school_only_sum_dup_month = df_closure_tod_wkday_school_only_sum_dup\n",
    "df_closure_tod_wkday_school_only_sum_dup_month['mean_monthly_steps_school_sum_per_month'] = df_closure_tod_wkday_school_only_sum_dup_month.groupby(['Month_Year_Name'])['mean_monthly_steps_school_sum'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup = df_closure_tod_wkday_school_only_sum_dup_month.drop_duplicates(subset=['mean_monthly_steps_school_sum_per_month', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "# Min\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].min()\n",
    "\n",
    "# Max\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].std()\n",
    "\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "steps_pre_closure_wkday_school_only_sum_dup = df_closure_tod_wkday_school_only_sum_dup[df_closure_tod_wkday_school_only_sum_dup['closure_status'] == 'Pre Closure']\n",
    "steps_pre_closure_wkday_school_only_sum_dup['Monthly_Avg'] = steps_pre_closure_wkday_school_only_sum_dup.groupby(['Month_Year_Name'])['mean_monthly_steps_school_sum'].transform('mean')\n",
    "steps_pre_closure_wkday_school_only_sum_dup['month_num'] = steps_pre_closure_wkday_school_only_sum_dup['Start_Time_Offset'].dt.month\n",
    "steps_pre_closure_wkday_school_only_sum_dup = steps_pre_closure_wkday_school_only_sum_dup.sort_values(by=['month_num'])\n",
    "steps_pre_closure_wkday_school_only_sum_col_dup = steps_pre_closure_wkday_school_only_sum_dup[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_pre_closure_wkday_school_only_sum_col_dup = steps_pre_closure_wkday_school_only_sum_col_dup.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "steps_dur_closure_wkday_school_only_sum_dup = df_closure_tod_wkday_school_only_sum_dup[df_closure_tod_wkday_school_only_sum_dup['closure_status'] == 'During Closure']\n",
    "steps_dur_closure_wkday_school_only_sum_dup['Monthly_Avg'] = steps_dur_closure_wkday_school_only_sum_dup.groupby(['Month_Year_Name'])['mean_monthly_steps_school_sum'].transform('mean')\n",
    "steps_dur_closure_wkday_school_only_sum_dup['month_num'] = steps_dur_closure_wkday_school_only_sum_dup['Start_Time_Offset'].dt.month\n",
    "steps_dur_closure_wkday_school_only_sum_dup = steps_dur_closure_wkday_school_only_sum_dup.sort_values(by=['month_num'])\n",
    "steps_dur_closure_wkday_school_only_sum_col_dup = steps_dur_closure_wkday_school_only_sum_dup[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_dur_closure_wkday_school_only_sum_col_dup = steps_dur_closure_wkday_school_only_sum_col_dup.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "steps_dur_closure_wkday_school_only_sum_col_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "U1, p = mannwhitneyu(steps_dur_closure_wkday_school_only_sum_col_dup['Monthly_Avg'],\n",
    "                     steps_pre_closure_wkday_school_only_sum_col_dup['Monthly_Avg'])\n",
    "print(U1)\n",
    "print(p*100)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sleep\n",
    "df_sleep = df[df['Type'] == 'sleepDuration']\n",
    "len(df_sleep)\n",
    "\n",
    "df_sleep['User UUID'].nunique()\n",
    "\n",
    "steps_user_id_list = df_valid_days_daycount['User UUID'].nunique()\n",
    "\n",
    "df_sleep_step_ids = df_sleep[df_sleep['User UUID'].isin(steps_user_id_list)]\n",
    "df_sleep_step_ids\n",
    "\n",
    "df_sleep_step_ids['User UUID'].nunique()\n",
    "\n",
    "df_valid_days_daycount['User UUID'].nunique()\n",
    "\n",
    "df_valid_days_daycount['User UUID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_step_ids['Start Time'] = df_sleep_step_ids['Start Time'].apply(pd.to_datetime)\n",
    "df_sleep_step_ids['End Time'] = df_sleep_step_ids['End Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_sleep_step_ids['Start Time Offset'] = df_sleep_step_ids['Start Time'] + pd.to_timedelta(df_sleep_step_ids['Time Zone Offset'], unit='m')\n",
    "df_sleep_step_ids['End Time Offset'] = df_sleep_step_ids['End Time'] + pd.to_timedelta(df_sleep_step_ids['Time Zone Offset'], unit='m')\n",
    "\n",
    "df_sleep_step_ids['Start Time Date Offset'] = df_sleep_step_ids['Start Time Offset'].dt.date\n",
    "df_sleep_step_ids['End Time Date Offset'] = df_sleep_step_ids['End Time Offset'].dt.date\n",
    "df_sleep_step_ids['month_year'] = df_sleep_step_ids['Start Time Offset'].dt.to_period('M')\n",
    "\n",
    "df_sleep_step_ids['Mon Year'] = df_sleep_step_ids['Start Time Offset'].dt.strftime('%b-%Y')\n",
    "df_sleep_step_ids['Month Year Name'] = df_sleep_step_ids['Mon Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_copy = df_sleep_step_ids\n",
    "df_sleep_copy_dup = df_sleep_copy.drop_duplicates(subset=['User UUID', 'Start Time', 'End Time', 'Value'], keep='first')\n",
    "df_sleep_copy_dup\n",
    "\n",
    "df_sleep_copy_dup['User UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_copy_dup['year_only'] = df_sleep_copy_dup['Start Time Offset'].dt.year\n",
    "df_sleep_copy_dup['month_only'] = df_sleep_copy_dup['Start Time Offset'].dt.strftime(\"%B\")\n",
    "df_sleep_copy_dup['Start Time Only Time'] = df_sleep_copy_dup['Start Time Offset'].dt.strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Convert to datetime format to calculate bedtime date\n",
    "df_sleep_copy_dup['Start Time Only Time Datetime'] = df_sleep_copy_dup['Start Time Only Time'].apply(pd.to_datetime)\n",
    "\n",
    "# Get only nighttime values\n",
    "# diff=445416-410584\n",
    "# change based on today's date\n",
    "df_sleep_bedtime_calc_allnight = df_sleep_copy_dup[(df_sleep_copy_dup['Start Time Only Time Datetime'] > dt.datetime(2023, 6, 27, 18, 0, 0)) &\n",
    "                                                   (df_sleep_copy_dup['Start Time Only Time Datetime'] < dt.datetime(2023, 6, 27, 8, 0, 0))]\n",
    "\n",
    "df_sleep_bedtime_calc_allnight['Start Time Only Time Datetime'].dt.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why twice?\n",
    "df_sleep_bedtime_calc_allnight['Start Time Only Time Datetime'] = df_sleep_bedtime_calc_allnight['Start Time Only Time'].apply(pd.to_datetime)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val = df_sleep_bedtime_calc_allnight\n",
    "# change according to today's date\n",
    "df_sleep_bedtime_calc_allnight_val.loc[(df_sleep_bedtime_calc_allnight_val['Start Time Only Time Datetime'] \n",
    "                                        > dt.datetime(2023, 6, 27, 18, 0, 0)), 'Bedtime_Date'] = \n",
    "df_sleep_bedtime_calc_allnight_val['Start Time_Date_Offset']\n",
    "df_sleep_bedtime_calc_allnight_val.loc[(df_sleep_bedtime_calc_allnight_val['Start Time Only Time Datetime'] \n",
    "                                        < dt.datetime(2023, 6, 27, 18, 0, 0)), 'Bedtime_Date'] = \n",
    "df_sleep_bedtime_calc_allnight_val['Start_Time_Date_Offset'] - timedelta(days=1)\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Start Time_Offset_dt'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['Start Time_Offset'])\n",
    "df_sleep_bedtime_calc_allnight_val['End Time_Offset_dt'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['End Time_Offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_bedtime_calc_allnight_val['Start_Time_Offset_dt'] = df_sleep_bedtime_calc_allnight_val['Start_Time_Offset_dt'].astype('int64') // 1e9\n",
    "df_sleep_bedtime_calc_allnight_val['End_Time_Offset_dt'] = df_sleep_bedtime_calc_allnight_val['End_Time_Offset_dt'].astype('int64') // 1e9\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso'] = df_sleep_bedtime_calc_allnight_val.groupby(['User UUID', 'Bedtime_Date'])['Start_Time_Offset_dt_iso'].transform('min')\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso'] = df_sleep_bedtime_calc_allnight_val.groupby(['User UUID', 'Bedtime_Date'])['End_Time_Offset_dt_iso'].transform('max')\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso'], unit='s')\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso'], unit='s')\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted_dt'] = df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted'].apply(pd.to_datetime)\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted_dt'] = df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted'].apply(pd.to_datetime)\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted_dt'].strftime(\"%H:%M:%S\")\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted_dt'].strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import rect, phase\n",
    "from math import radians, degrees\n",
    "\n",
    "def meanAngle(deg):\n",
    "    complexDegree = sum(rect(1, radians(d)) for d in deg) / len(deg)\n",
    "    argument = phase(complexDegree)\n",
    "    meanAngle = degrees(argument)\n",
    "    return meanAngle\n",
    "\n",
    "def meanTime(times):\n",
    "    t = (time.split(':') for time in times)\n",
    "    seconds = sum((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n",
    "    \n",
    "    day = 24 * 60 * 60\n",
    "    toAngles = [s * 360. / day for s in seconds]\n",
    "    meanAsAngle = meanAngle(toAngles)\n",
    "    meanSeconds = meanAsAngle * day / 360.\n",
    "    \n",
    "    if meanSeconds < 0:\n",
    "        meanSeconds += day\n",
    "    h, m = divmod(meanSeconds, 3600)\n",
    "    m, s = divmod(m, 60)\n",
    "    \n",
    "    return '%02i:%02i:%02i' % (h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_bedtime_calc_allnight_val_copy = df_sleep_bedtime_calc_allnight_val\n",
    "\n",
    "# get month from bedtime\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date_month_year'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date']).dt.to_period('M')\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date_month_year_abb'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date']).dt.strftime('%b')\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date_month_year']\n",
    "\n",
    "# Do we need this?\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Mon_Year_Bedtime'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date']).dt.strftime('%b-%Y')\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Month_Year_Name_Bedtime'] = df_sleep_bedtime_calc_allnight_val_copy['Mon_Year_Bedtime']\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Month_Year_Name_Bedtime'] = df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date\n",
    "df_sleep_bedtime_calc_allnight_val_copy.loc[(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date < dt.date(2020, 3, 15)) &\n",
    "                                            (df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date >= dt.date(2020, 3, 1)),\n",
    "                                            'Month_Year_Name_Bedtime'] = '1-14 Mar-2020'\n",
    "df_sleep_bedtime_calc_allnight_val_copy.loc[(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date < dt.date(2020, 4, 1)) &\n",
    "                                            (df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date >= dt.date(2020, 3, 15)),\n",
    "                                            'Month_Year_Name_Bedtime'] = '15-31 Mar-2020'\n",
    "df_sleep_bedtime_calc_allnight_val_copy.loc[(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date < dt.date(2020, 4, 1)),\n",
    "                                            'Month_Year_Name_Bedtime'] = df_sleep_bedtime_calc_allnight_val_copy.Month_Year_Name_Bedtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_bt = df_sleep_bedtime_calc_allnight_val_copy.columns.values\n",
    "df_sleep_bedtime_calc_allnight_val_mean = pd.DataFrame(columns=column_names_bt)\n",
    "\n",
    "unique_id_avg = df_sleep_bedtime_calc_allnight_val_copy['User UUID'].unique()\n",
    "\n",
    "for i in unique_id_avg:\n",
    "    df_id_avg = df_sleep_bedtime_calc_allnight_val_copy[df_sleep_bedtime_calc_allnight_val_copy['User UUID'] == i]\n",
    "    print(i)\n",
    "\n",
    "    unique_month = df_id_avg['Month_Year_Name_Bedtime'].unique()\n",
    "\n",
    "    for j in unique_month:\n",
    "        df_id_date_avg = df_id_avg[df_id_avg['Month_Year_Name_Bedtime'] == j]\n",
    "        df_id_date_avg['Average Bedtime'] = meanTime(df_id_date_avg['Bedtime_Min_iso_int_converted_time'])\n",
    "\n",
    "        # Calculate average wake time.\n",
    "        df_id_date_avg['Average Waketime'] = meanTime(df_id_date_avg['Waketime_Max_iso_int_converted_time'])\n",
    "\n",
    "        # Append the average date calculations back to the main dataframe.\n",
    "        df_sleep_bedtime_calc_allnight_val_mean = df_sleep_bedtime_calc_allnight_val_mean.append(df_id_date_avg)\n",
    "\n",
    "# Restrict the time to a specific range and print the minimum and maximum dates.\n",
    "df_sleep_bedtime_calc_allnight_val_mean = df_sleep_bedtime_calc_allnight_val_mean[\n",
    "    (df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'] > dt.date(2019, 3, 1)) &\n",
    "    (df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'] <= dt.date(2021, 6, 30))\n",
    "]\n",
    "\n",
    "print(df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'].min())\n",
    "print(df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dleep_bedtime_calc_allnight_val_mean.loc[(df_dleep_bedtime_calc_allnight_val_mean['Bedtime_Date']<dt.date(2020,3,15))\n",
    "                                            &(df_dleep_bedtime_calc_allnight_val_mean['Bedtime_Date']>dt.date(2019,3,15))]\n",
    "\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_mean.loc[\n",
    "    (df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'] < dt.date(2020, 3, 15)) & \n",
    "    (df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'] >= dt.date(2019, 3, 1)),\n",
    "    'closure_status'] = 'Pre Closure'\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_mean.loc[\n",
    "    (df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'] <= dt.date(2021, 3, 31)) & \n",
    "    (df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'] >= dt.date(2020, 3, 15)),\n",
    "    'closure_status'] = 'During Closure'\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_mean.loc[\n",
    "    (df_sleep_bedtime_calc_allnight_val_mean['Bedtime Date'] > dt.date(2021, 3, 1))]\n",
    "    ,'closure_status'] = 'Post Closure'\n",
    "\n",
    "                                                                                                                         \n",
    "                                                                                                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print the minimum bedtime date grouped by 'closure_status'\n",
    "print(df_sleep_bedtime_calc_allnight_val_mean.groupby('closure_status')['Bedtime Date'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start of new calculation using the same approach as step  avg\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_mean_dup = df_sleep_bedtime_calc_allnight_val_mean.drop_duplicates(subset=['User UUID', 'Month_Year_Name_Bedtime'], keep='first')\n",
    "\n",
    "\n",
    "column_names_avg = df_sleep_bedtime_calc_allnight_val_mean_dup.columns.values\n",
    "df_avg_per_month = pd.DataFrame(columns=column_names_avg)\n",
    "\n",
    "# Extracting unique month-year combinations\n",
    "month_avg = df_sleep_bedtime_calc_allnight_val_mean_dup['Month_Year_Name_Bedtime'].unique()\n",
    "j = 0  # 'j' is initialized but not used in the visible code\n",
    "\n",
    "# Looping through each month for further calculations\n",
    "for i in month_avg:\n",
    "    df_month_avg = \n",
    "    df_sleep_bedtime_calc_allnight_val_mean_dup[df_sleep_bedtime_calc_allnight_val_mean_dup['Month_Year_Name_Bedtime'] == i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_avg = df_sleep_bedtime_calc_allnight_val_mean_dup.columns.values\n",
    "df_avg_per_month = pd.DataFrame(columns=column_names_avg)\n",
    "\n",
    "# Getting unique 'Month_Year_Name_Bedtime' values from the data.\n",
    "month_avg = df_sleep_bedtime_calc_allnight_val_mean_dup['Month_Year_Name_Bedtime'].unique()\n",
    "\n",
    "# Loop through each month-year to calculate average bedtime and waketime per period.\n",
    "for i in month_avg:\n",
    "    df_month_avg = df_sleep_bedtime_calc_allnight_val_mean_dup[df_sleep_bedtime_calc_allnight_val_mean_dup['Month_Year_Name_Bedtime'] == i]\n",
    "    df_month_avg['Average_Bedtime_per_period'] = meanTime(df_month_avg['Average Bedtime'])\n",
    "    df_month_avg['Average_Waketime_per_period'] = meanTime(df_month_avg['Average Waketime'])\n",
    "    print(i)\n",
    "\n",
    "    # Appending the monthly averages to the main DataFrame.\n",
    "    df_avg_per_month = df_avg_per_month.append(df_month_avg)\n",
    "\n",
    "# Deduplicating the data based on 'Average_Bedtime_per_period' and 'Month_Year_Name_Bedtime'.\n",
    "df_avg_per_month_bt_dup = df_avg_per_month.drop_duplicates(subset=['Average_Bedtime_per_period', 'Month_Year_Name_Bedtime'], keep='first')\n",
    "\n",
    "# Deduplicating the data based on 'Average_Waketime_per_period' and 'Month_Year_Name_Bedtime'.\n",
    "df_avg_per_month_wt_dup = df_avg_per_month.drop_duplicates(subset=['Average_Waketime_per_period', 'Month_Year_Name_Bedtime'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-pandemic bedtime and waketime are being filtered from the data.\n",
    "Pre_pandemic_bt = df_avg_per_month_bt_dup[df_avg_per_month_bt_dup['closure_status'] == 'Pre Closure']\n",
    "Pre_pandemic_wt = df_avg_per_month_wt_dup[df_avg_per_month_wt_dup['closure_status'] == 'Pre Closure']\n",
    "\n",
    "# Calculating pre and post-pandemic mean bedtime and waketime.\n",
    "Post_pandemic_bt = df_avg_per_month_bt_dup[df_avg_per_month_bt_dup['closure_status'] == 'During Closure']\n",
    "Post_pandemic_wt = df_avg_per_month_wt_dup[df_avg_per_month_wt_dup['closure_status'] == 'During Closure']\n",
    "\n",
    "meanTime(Pre_pandemic_bt['Average_Bedtime_per_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTime(Pre_pandemic_wt['Average_Waketime_per_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTime(Post_pandemic_wt['Average_Waketime_per_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTime(Post_pandemic_bt['Average_Bedtime_per_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanTime_a(times, type):\n",
    "    t = [(time.split(':')) for time in times]\n",
    "    seconds = [((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)]\n",
    "    day = 24 * 60 * 60\n",
    "    toAngles = [s * 360.0 / day for s in seconds]\n",
    "\n",
    "    x = [(ang + 360) if (ang < 120 and type == 'Night') else ang for ang in toAngles]\n",
    "    mean = (np.mean(x) - 360) if np.mean(x) > 360 else np.mean(x)\n",
    "    std = (np.std(x) - 360) if np.std(x) > 360 else np.std(x)\n",
    "\n",
    "    print(x)\n",
    "    print(mean)\n",
    "    print(std)\n",
    "\n",
    "    for val in [mean, std]:\n",
    "        meanSeconds = val * day / 360.0\n",
    "        if meanSeconds < 0:\n",
    "            meanSeconds += day\n",
    "        h, m = divmod(meanSeconds, 3600)\n",
    "        m, s = divmod(m, 60)\n",
    "        print(f'{int(h):02d}:{int(m):02d}:{int(s):02d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing pre-pandemic bedtime data\n",
    "Pre_pandemic_bt_sum = Pre_pandemic_bt[Pre_pandemic_bt['Month_Year_Name_Bedtime'].isin(['Jun-2019', 'Jul-2019', 'Aug-2019'])]\n",
    "Pre_pandemic_bt_sum = Pre_pandemic_bt_sum[['Average_Bedtime_per_period', 'Month_Year_Name_Bedtime']]\n",
    "\n",
    "# Calculating mean time for pre-pandemic bedtime\n",
    "meanTime(Pre_pandemic_bt_sum['Average_Bedtime_per_period'])\n",
    "\n",
    "# Calculating mean time for pre-pandemic bedtime at night\n",
    "meanTime_a(Pre_pandemic_bt_sum['Average_Bedtime_per_period'], 'Night')\n",
    "\n",
    "# Summarizing pre-pandemic waketime data\n",
    "Pre_pandemic_wt_sum = Pre_pandemic_wt[Pre_pandemic_wt['Month_Year_Name_Bedtime'].isin(['Jun-2019', 'Jul-2019', 'Aug-2019'])]\n",
    "Pre_pandemic_wt_sum = Pre_pandemic_wt_sum[['Average_Waketime_per_period', 'Month_Year_Name_Bedtime']]\n",
    "\n",
    "# Calculating mean time for pre-pandemic waketime\n",
    "meanTime(Pre_pandemic_wt_sum['Average_Waketime_per_period'])\n",
    "\n",
    "# Calculating mean time for pre-pandemic waketime during the day\n",
    "meanTime_a(Pre_pandemic_wt_sum['Average_Waketime_per_period'], 'Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding average bedtime to the nearest 15 minutes\n",
    "df_avg_per_month_bt_dup = df_sleep_bedtime_calc_allnight_val_mean_dup\n",
    "df_avg_per_month_bt_dup['Average_Bedtime_Round_fifteenmin'] = pd.to_datetime(\n",
    "    pd.to_datetime(df_avg_per_month_bt_dup['Average_Bedtime'], format=\"%H:%M:%S\").dt.round('15min')\n",
    ").dt.strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Rounding average waketime to the nearest 15 minutes\n",
    "df_avg_per_month_wt_dup = df_sleep_bedtime_calc_allnight_val_mean_dup\n",
    "df_avg_per_month_wt_dup['Average_Waketime_Round_fifteenmin'] = pd.to_datetime(\n",
    "    pd.to_datetime(df_avg_per_month_wt_dup['Average_Waketime'], format=\"%H:%M:%S\").dt.round('15min')\n",
    ").dt.strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_per_month_bt_dup['Average_Bedtime_Round_fifteenmin'].unique()\n",
    "\n",
    "# Extracting hours and minutes from the rounded bedtime, converting them to strings\n",
    "df_avg_per_month_bt_dup['bt_hr'] = df_avg_per_month_bt_dup['Average_Bedtime_Round_fifteenmin'].dt.strftime(\"%H\").astype(str)\n",
    "df_avg_per_month_bt_dup['bt_min'] = df_avg_per_month_bt_dup['Average_Bedtime_Round_fifteenmin'].dt.strftime(\"%M\").astype(str)\n",
    "\n",
    "# Converting these to a floating-point representation\n",
    "df_avg_per_month_bt_dup['bt_float'] = df_avg_per_month_bt_dup['bt_hr'] + '.' + df_avg_per_month_bt_dup['bt_min']\n",
    "\n",
    "\n",
    "# Similar steps are taken for the waketime data\n",
    "df_avg_per_month_wt_dup['wt_hr'] = df_avg_per_month_wt_dup['Average_Waketime_Round_fifteenmin'].dt.strftime(\"%H\").astype(str)\n",
    "df_avg_per_month_wt_dup['wt_min'] = df_avg_per_month_wt_dup['Average_Waketime_Round_fifteenmin'].dt.strftime(\"%M\").astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_per_month_wt_dup_order = df_avg_per_month_wt_dup\n",
    "df_avg_per_month_wt_dup_order['wt_float'] = df_avg_per_month_wt_dup_order['wt_float'].astype(float)\n",
    "df_avg_per_month_wt_dup_order['flip_wake'] = 0\n",
    "\n",
    "\n",
    "df_avg_per_month_wt_dup_order.loc[df_avg_per_month_wt_dup_order['wt_float'] < 12, 'flip_wake'] = \\\n",
    "    df_avg_per_month_wt_dup_order['wt_float'] + 12\n",
    "\n",
    "\n",
    "df_avg_per_month_wt_dup_order_fig2 = df_avg_per_month_wt_dup_order.drop_duplicates(\n",
    "    subset=['User UUID', 'Average_Waketime_Round_fifteenmin', 'Month_Year_Name_Bedtime'],\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "len(df_avg_per_month_wt_dup_order_fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(95, 35))\n",
    "sns.set(font_scale=8)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Defining the color palette for the plot based on the 'closure_status'.\n",
    "palette = {\n",
    "    'Pre Closure': \"indianred\",\n",
    "    'During Closure': \"gold\"\n",
    "}\n",
    "\n",
    "# Creating a boxplot that displays the distribution of 'flip_wake' times across months,\n",
    "# differentiated by 'closure_status'.\n",
    "ax = sns.boxplot(\n",
    "    x='month_only', \n",
    "    y='flip_wake',\n",
    "    data=fig_2_sort_wake,\n",
    "    hue=\"closure_status\",\n",
    "    palette=palette,\n",
    "    linewidth=12,\n",
    "    showfliers=False  # This disables showing outliers in the plot.\n",
    ")\n",
    "\n",
    "# Customizing tick labels and adding labels for x and y axes with specific font sizes and weights.\n",
    "plt.setp(ax.get_xticklabels(), rotation=0)\n",
    "ax.set_xlabel(\"\", fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=-4.5)\n",
    "ax.set_ylabel(\"Average Daily Wake Time\", fontdict={'fontsize': 100, 'fontweight': 'bold'})\n",
    "\n",
    "# Setting the title of the plot with a specific font size and weight.\n",
    "ax.set_title(\n",
    "    \"Average Daily Wake Times By Month (rounded to nearest 15 mins) for Participants (Night Sleep)\",\n",
    "    fontdict={'fontsize': 90, 'fontweight': 'bold'},\n",
    "    y=1.03  # Adjusting the vertical position of the title.\n",
    ")\n",
    "\n",
    "# Customizing the legend of the plot with specific font sizes for text and title.\n",
    "plt.legend(\n",
    "    loc=\"upper right\",\n",
    "    fontsize=70,\n",
    "    title=\"Year\",\n",
    "    framealpha=0.5\n",
    ")\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='80')  # Setting font size for Legend text.\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='80') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_per_month_bt_dup_order = df_avg_per_month_bt_dup\n",
    "\n",
    "# Converting the 'bt_float' column to float and initializing 'flip' column.\n",
    "df_avg_per_month_bt_dup_order['bt_float'] = df_avg_per_month_bt_dup_order['bt_float'].astype(float)\n",
    "df_avg_per_month_bt_dup_order['flip'] = 0\n",
    "\n",
    "# The code seems to be adjusting the 'flip' value based on the time of day.\n",
    "df_avg_per_month_bt_dup_order.loc[df_avg_per_month_bt_dup_order['bt_float'] > 12, 'flip'] = \\\n",
    "    df_avg_per_month_bt_dup_order['bt_float'] - 12\n",
    "df_avg_per_month_bt_dup_order.loc[df_avg_per_month_bt_dup_order['bt_float'] < 12, 'flip'] = \\\n",
    "    df_avg_per_month_bt_dup_order['bt_float'] + 12\n",
    "\n",
    "# Dropping duplicates from the DataFrame for a cleaner dataset.\n",
    "df_avg_per_month_bt_dup_order_fig2 = df_avg_per_month_bt_dup_order.drop_duplicates(\n",
    "    subset=['User UUID', 'Average_Bedtime_Round_fifteenmin', 'Month_Year_Name_Bedtime'], \n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "# Displaying the DataFrame or storing it for further analysis or visualization.\n",
    "df_avg_per_month_bt_dup_order_fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2_sort = df_avg_per_month_bt_dup_order_fig2\n",
    "\n",
    "# Filtering the DataFrame for entries during 'During Closure' and 'Pre Closure'\n",
    "fig_2_sort = fig_2_sort[\n",
    "    (fig_2_sort['closure_status'] == 'During Closure') | \n",
    "    (fig_2_sort['closure_status'] == 'Pre Closure')\n",
    "]\n",
    "\n",
    "# Creating a 'Bedtime Date Month Closure' column based on the 'Month_Year_Name_Bedtime' column\n",
    "fig_2_sort['Bedtime_Date_Month_Closure'] = fig_2_sort['Month_Year_Name_Bedtime'].str[0:3]\n",
    "\n",
    "# Setting specific date ranges for the 'Bedtime_Date_Month_Closure' based on conditions\n",
    "fig_2_sort.loc[fig_2_sort['Month_Year_Name_Bedtime'] == '1-14 Mar-2020', 'Bedtime_Date_Month_Closure'] = 'Mar'\n",
    "fig_2_sort.loc[fig_2_sort['Month_Year_Name_Bedtime'] == '15-31 Mar-2020', 'Bedtime_Date_Month_Closure'] = 'Mar'\n",
    "\n",
    "# Converting 'Bedtime Date Month Closure' to a categorical type with an ordered list of months\n",
    "fig_2_sort['month_only'] = pd.Categorical(\n",
    "    fig_2_sort['Bedtime_Date_Month_Closure'],\n",
    "    categories=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "    ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(95, 35))\n",
    "sns.set(font_scale=8)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Defining the color palette for different closure statuses\n",
    "palette = {\n",
    "    'Pre Closure': \"steelblue\",\n",
    "    'During Closure': \"skyblue\",\n",
    "    'Post Closure': \"salmon\"\n",
    "}\n",
    "\n",
    "# Creating a seaborn boxplot for the 'month_only' and 'flip' columns in the fig_2_sort DataFrame\n",
    "ax = sns.boxplot(\n",
    "    x='month_only',\n",
    "    y='flip',\n",
    "    data=fig_2_sort,\n",
    "    hue='closure_status',\n",
    "    palette=palette,\n",
    "    linewidth=12,\n",
    "    showfliers=False  # This option removes the outliers from the plot.\n",
    ")\n",
    "\n",
    "# Customization of tick labels, including rotation for better readability\n",
    "plt.setp(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "\n",
    "# Customizing the labels and title of the plot with specified font sizes and weights\n",
    "ax.set_xlabel(\"\", fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=-4.5)\n",
    "ax.set_ylabel(\"Average Daily Bed Time\", fontdict={'fontsize': 100, 'fontweight': 'bold'})\n",
    "ax.set_title(\n",
    "    \"Average Daily Sleep Times By Month (rounded to nearest 15 mins) for Participants\",\n",
    "    fontdict={'fontsize': 90, 'fontweight': 'bold'},\n",
    "    y=1.03\n",
    ")\n",
    "\n",
    "# Setting up the legend of the plot, including its location, font size, and title\n",
    "plt.legend(\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1.01, 0.5),\n",
    "    frameon=True,\n",
    "    fontsize=80,\n",
    "    title=\"Year\",\n",
    "    framealpha=0.5\n",
    ")\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='80')  # Font size for Legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='80') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_bedtime_calc_allnight_val_mean_order['flip_wake'] = 0\n",
    "\n",
    "# Adjust 'flip_wake' based on the 'Average_Waketime_Round_thirtymin_Float' value being greater than 12\n",
    "df_sleep_bedtime_calc_allnight_val_mean_order.loc[\n",
    "    (df_sleep_bedtime_calc_allnight_val_mean_order['Average_Waketime_Round_thirtymin_Float'] > 12),\n",
    "    'flip_wake'\n",
    "] = df_sleep_bedtime_calc_allnight_val_mean_order['Average_Waketime_Round_thirtymin_Float'] - 12\n",
    "\n",
    "# Adjust 'flip_wake' when the 'Average_Waketime_Round_thirtymin_Float' value is less than 12\n",
    "df_sleep_bedtime_calc_allnight_val_mean_order.loc[\n",
    "    (df_sleep_bedtime_calc_allnight_val_mean_order['Average_Waketime_Round_thirtymin_Float'] < 12),\n",
    "    'flip_wake'\n",
    "] = df_sleep_bedtime_calc_allnight_val_mean_order['Average_Waketime_Round_thirtymin_Float'] + 12\n",
    "\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_mean_order[['flip', 'Average_Bedtime_Round_thirtymin_Float']]\n",
    "df_sleep_bedtime_calc_allnight_val_mean_order[['flip_wake', 'Average_Waketime_Round_thirtymin_Float']]\n",
    "\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_mean_order['flip'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_bedtime_calc_allnight_val_mean_order = df_sleep_bedtime_calc_allnight_val_mean\n",
    "\n",
    "# Initializing a new DataFrame for sleep duration calculations\n",
    "df_sleep_duration = df_sleep_bedtime_calc_allnight_val_mean_order\n",
    "\n",
    "# Calculating the total sleep per day by summing up values grouped by 'Bedtime Date' and 'User UUID'\n",
    "df_sleep_duration['Total Sleep Per Day Bedtime'] = df_sleep_duration.groupby(['Bedtime Date', 'User UUID'])['Value'].transform('sum')\n",
    "\n",
    "# Converting the 'Total Sleep Per Day Bedtime' to a float\n",
    "df_sleep_duration['Total Sleep Per Day Bedtime float'] = df_sleep_duration['Total Sleep Per Day Bedtime'].astype(float)\n",
    "\n",
    "# Calculating the average monthly sleep duration by grouping by 'User UUID' and 'Month_Year_Name_Bedtime'\n",
    "df_sleep_duration['Average Monthly Sleep Duration Bedtime'] = df_sleep_duration.groupby(['User UUID', 'Month_Year_Name_Bedtime'])['Total Sleep Per Day Bedtime float'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get unique 'Month_Year_Name_Bedtime' values from the DataFrame\n",
    "unique_month_year_bedtime = df_sleep_duration_fig1['Month_Year_Name_Bedtime'].unique()\n",
    "\n",
    "# Calculating the minimum average monthly sleep duration by 'closure_status'\n",
    "min_sleep_duration_by_status = df_sleep_duration_fig1.groupby('closure_status')['Average Monthly Sleep Duration Bedtime'].min()\n",
    "\n",
    "# Calculating the maximum average monthly sleep duration by 'closure_status'\n",
    "max_sleep_duration_by_status = df_sleep_duration_fig1.groupby('closure_status')['Average Monthly Sleep Duration Bedtime'].max()\n",
    "\n",
    "# Calculating the mean average monthly sleep duration by 'closure_status'\n",
    "mean_sleep_duration_by_status = df_sleep_duration_fig1.groupby('closure_status')['Average Monthly Sleep Duration Bedtime'].mean()\n",
    "\n",
    "# Calculating the standard deviation of the average monthly sleep duration by 'closure_status'\n",
    "std_sleep_duration_by_status = df_sleep_duration_fig1.groupby('closure_status')['Average Monthly Sleep Duration Bedtime'].std()\n",
    "\n",
    "# Calculating the number of unique users in each 'closure_status' group\n",
    "user_count_by_status = df_sleep_duration_fig1.groupby('closure_status')['User UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to count unique users for each 'closure_status'\n",
    "user_count_by_closure_status = df_sleep_duration_fig1.groupby('closure_status')['User UUID'].nunique()\n",
    "\n",
    "# Calculating the mean sleep duration per month\n",
    "df_sleep_duration_month = df_sleep_duration\n",
    "df_sleep_duration_month['Avg_Sleep_Duration_Per_Month'] = df_sleep_duration_month.groupby(['Month_Year_Name_Bedtime'])['Average Monthly Sleep Duration_Bedtime'].transform('mean')\n",
    "\n",
    "# Dropping duplicates to get one mean value per month\n",
    "df_sleep_duration_month = df_sleep_duration_month.drop_duplicates(subset=['Avg_Sleep_Duration_Per_Month', 'Month_Year_Name_Bedtime'], keep='first')\n",
    "df_sleep_duration_month\n",
    "\n",
    "# Calculating the minimum average sleep duration per month grouped by 'closure_status'\n",
    "min_sleep_duration_per_month_by_status = df_sleep_duration_month.groupby('closure_status')['Avg_Sleep_Duration_Per_Month'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the standard deviation of the average sleep duration per month grouped by 'closure_status'\n",
    "std_sleep_duration_per_month_by_status = df_sleep_duration_month.groupby('closure_status')['Avg_Sleep_Duration_Per_Month'].std()\n",
    "\n",
    "# Preparing the data for a statistical test related to 'Pre Closure'\n",
    "sleep_pre_closure = df_sleep_duration_month[df_sleep_duration_month['closure_status'] == \"Pre Closure\"]\n",
    "sleep_pre_closure['Bedtime_Date'] = pd.to_datetime(sleep_pre_closure['Bedtime_Date'])\n",
    "sleep_pre_closure['month_num'] = sleep_pre_closure['Bedtime_Date'].dt.month\n",
    "sleep_pre_closure = sleep_pre_closure.sort_values(by=['month_num'])\n",
    "\n",
    "# Dropping duplicates to prepare for statistical analysis\n",
    "sleep_pre_closure_dup = sleep_pre_closure.drop_duplicates(subset=['Avg_Sleep_Duration_Per_Month', 'Month_Year_Name_Bedtime'], keep='first')\n",
    "sleep_pre_closure_dup = sleep_pre_closure_dup[['Avg_Sleep_Duration_Per_Month', 'Month_Year_Name_Bedtime']]\n",
    "sleep_pre_closure_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Performing a Mann-Whitney U Test on sleep duration data\n",
    "U1, p = mannwhitneyu(\n",
    "    sleep_dur_closure_dup['Avg_Sleep_Duration_Per_Month'],\n",
    "    sleep_pre_closure_dup['Avg_Sleep_Duration_Per_Month']\n",
    ")\n",
    "print(U1)\n",
    "print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a sorted DataFrame for visualization\n",
    "fig_duration_sort = df_sleep_duration_fig1\n",
    "fig_duration_sort = fig_duration_sort[\n",
    "    (fig_duration_sort['closure_status'] == 'During Closure') |\n",
    "    (fig_duration_sort['closure_status'] == 'Pre Closure')\n",
    "]\n",
    "\n",
    "# Setting 'Bedtime_Date_Month_Closure' and categorizing 'month_only'\n",
    "fig_duration_sort['Bedtime_Date_Month_Closure'] = fig_duration_sort['Month_Year_Name_Bedtime'].str[0:3]\n",
    "fig_duration_sort.loc[(fig_duration_sort['Month_Year_Name_Bedtime'] == '1-14 Mar-2020'), 'Bedtime_Date_Month_Closure'] = 'Mar'\n",
    "fig_duration_sort.loc[(fig_duration_sort['Month_Year_Name_Bedtime'] == '15-31 Mar-2020'), 'Bedtime_Date_Month_Closure'] = 'Mar'\n",
    "fig_duration_sort['month_only'] = pd.Categorical(\n",
    "    fig_duration_sort['Bedtime_Date_Month_Closure'],\n",
    "    categories=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "    ordered=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the figure size and style for the seaborn plot\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set(font_scale=8)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Define a color palette for the closure statuses\n",
    "palette = {\n",
    "    'Pre Closure': \"yellowgreen\",\n",
    "    'During Closure': \"pink\"\n",
    "}\n",
    "\n",
    "# Create a boxplot with seaborn\n",
    "ax = sns.boxplot(\n",
    "    x='month_only',\n",
    "    y='Average_Monthly_Sleep_Duration_Bedtime',\n",
    "    data=fig_duration_sort,\n",
    "    hue='closure_status',\n",
    "    palette=palette,\n",
    "    linewidth=14,\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "# Customize tick labels and set labels for axes and the plot title with specific font sizes and weights\n",
    "plt.setp(ax.get_xticklabels(), rotation=0)\n",
    "ax.set_xlabel(\"\", fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=-4.5)\n",
    "ax.set_ylabel(\"Average Daily Sleep Duration (Hours)\", fontdict={'fontsize': 100, 'fontweight': 'bold'})\n",
    "ax.set_title(\n",
    "    \"Average Daily Sleep Duration By Month (rounded to nearest 30 mins) for Participants (Night Sleep)\",\n",
    "    fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.03\n",
    ")\n",
    "\n",
    "# Configure the legend of the plot\n",
    "plt.legend(\n",
    "    loc=\"center left\", bbox_to_anchor=(1.01, 0.5),\n",
    "    frameon=True, fontsize=70,\n",
    "    title=\"Year\", framealpha=0.5\n",
    ")\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='90')  # Font size for Legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='90')  # Font size for Legend title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
