{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "\n",
    "from glob import iglob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'P:\\000868684 - Hearts and Parks\\Pattern Health Download\\Summer 2021 data download - post study closure\\**\\*.csv'\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for f in iglob(path, recursive=True)), ignore_index=True)\n",
    "\n",
    "# Get MMI data\n",
    "df_mmi = df[df['Type'] == 'meanMotionIntensity']\n",
    "\n",
    "df_mmi['Start Time'] = df_mmi['Start Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_mmi['End Time'] = df_mmi['End Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_mmi['Start_Time_Offset'] = df_mmi['Start Time'] + pd.to_timedelta(df_mmi['Time Zone Offset'], unit='s')\n",
    "df_mmi['End_Time_Offset'] = df_mmi['End Time'] + pd.to_timedelta(df_mmi['Time Zone Offset'], unit='s')\n",
    "\n",
    "# get steps data\n",
    "df_steps = df[df['Type'] == 'steps']\n",
    "df_steps['User UUID'].unique()\n",
    "\n",
    "df_steps['Start Time'] = df_steps['Start Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_steps['End Time'] = df_steps['End Time'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps['Start_Time_Offset'] = df_steps['Start Time'] + pd.to_timedelta(df_steps['Time Zone Offset'], unit='s')\n",
    "df_steps['End_Time_Offset'] = df_steps['End Time'] + pd.to_timedelta(df_steps['Time Zone Offset'], unit='s')\n",
    "\n",
    "# df['Start_Time_Offset'] = df.loc[:,['Start Time','Time Zone Offset']].sum(axis=1)\n",
    "\n",
    "df_merge_steps_mi = pd.merge(df_steps, df_mmi, left_on=['User UUID', 'Start_Time_Offset', 'End_Time_Offset'], right_on=['User UUID', 'Start_Time_Offset', 'End_Time_Offset'])\n",
    "df_merge_steps_mi['User UUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merge_steps_mi)\n",
    "\n",
    "df_merge_steps_mi\n",
    "\n",
    "df_merge_steps_mi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove value_y from duplicate subset\n",
    "df_merge_dup = df_merge_steps_mi.drop_duplicates(subset=['User UUID', 'Start_Time_Offset', 'End_Time_Offset', 'Value_x'], keep='first')\n",
    "df_merge_dup\n",
    "\n",
    "sixtyone_epoch = df_merge_dup[df_merge_dup['User UUID']=='u-22Kw0lWnvI27MXMuRggpVA']\n",
    "sixtyone_epoch = sixtyone_epoch[sixtyone_epoch['Start Time_x'] == '2021-02-28T15:45:00Z']\n",
    "sixtyone_epoch[['User UUID', 'End Time_x', 'End Time_y', 'Value_y', 'Value_x']]\n",
    "\n",
    "# sixtyone_epoch = df_merge_steps_mi[df_merge_steps_mi['User UUID'] == 'u-22Kw0lWnvI27MXMuRggpVA']\n",
    "# sixtyone_epoch[sixtyone_epoch['Start Time'] == '2021-02-28T15:45:00Z'][['User UUID', 'Start Time', 'End Time', 'Value']]\n",
    "\n",
    "# MMIT value is slightly different\n",
    "# sixtyone_epoch[sixtyone_epoch['Start Time_x'] == '2021-02-28T15:45:00Z']['Value_y'].unique()\n",
    "\n",
    "# df_merge_dup['User UUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_dup['End Time'] = df_merge_dup['End Time_x'].apply(pd.to_datetime)\n",
    "\n",
    "df_merge_dup['Start_Time_Date_Offset_x'] = df_merge_dup['Start Time Offset'].dt.date\n",
    "df_merge_dup['End_Time_Date_Offset_x'] = df_merge_dup['End Time Offset'].dt.date\n",
    "\n",
    "df_merge_dup['month_year'] = df_merge_dup['Start Time Offset'].dt.to_period('M')\n",
    "\n",
    "# df_merge_dup['Total_Steps_Per_Day'] = df_merge_dup.groupby(['Start_Time_Date_Offset_x', 'User UUID'])['Value_x'].transform(sum())\n",
    "\n",
    "df_merge_dup['Total_Steps_Per_Day_pre_missing'] = df_merge_dup.groupby(['Start_Time_Date_Offset_x', 'User UUID'])['Value_x'].transform('sum')\n",
    "\n",
    "# df_merge_steps_mi_dup_z_nz_2['Average_Monthly_Steps_pre_missing'] = df_merge_steps_mi_dup_z_nz_2.groupby([' User UUID', 'month_year'])['Total_Steps_Per_Day'].transform('mean')\n",
    "\n",
    "df_merge_dup['Mon_Year'] = df_merge_dup['Start_Time_Offset'].dt.strftime('%b-%Y')\n",
    "\n",
    "df_merge_dup['Month_Year_Name'] = df_merge_dup['Mon_Year']\n",
    "\n",
    "df_merge_dup.loc[(df_merge_dup['Start_Time_Date_Offset_x'] == dt.date(2020, 3, 15)), 'Month_Year_Name'] = '1-14 Mar-2020'\n",
    "df_merge_dup.loc[(df_merge_dup['Start_Time_Date_Offset_x'] > dt.date(2020, 3, 15)) & (df_merge_dup['Start_Time_Date_Offset_x'] <= dt.date(2020, 3, 31)), 'Month_Year_Name'] = '15-31 Mar-2020'\n",
    "df_merge_dup.loc[(df_merge_dup['Start_Time_Date_Offset_x'] == dt.date(2020, 4, 1)), 'Month_Year_Name'] = df_merge_dup.Month_Year_Name\n",
    "\n",
    "df_merge_dup['Average_Monthly_Steps_Lockdown_pre_missing'] = df_merge_dup.groupby(['User UUID', 'Month_Year_Name'])['Total_Steps_Per_Day_pre_missing'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero = df_merge_dup[df_merge_dup['Value_y'] < 1]\n",
    "df_zero['Value_y'].unique()\n",
    "\n",
    "df_non_zero = df_merge_dup[df_merge_dup['Value_y'] > 1]\n",
    "df_non_zero\n",
    "df_non_zero['User UUID'].unique()\n",
    "\n",
    "# Calculate missingness\n",
    "# df_steps_missing = df_merge_steps_mi_dup_non_zero\n",
    "df_steps_missing = df_non_zero\n",
    "\n",
    "df_steps_missing['Num_of_days'] = 0\n",
    "df_steps_missing['total_percent_missing'] = 0\n",
    "df_steps_missing['percent_missing_per_day'] = 0\n",
    "df_steps_missing['Epochs_per_day'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_steps_missing['Valid Day'] = 'no'\n",
    "df_steps_missing.loc[(df_steps_missing['Epochs_per_day'] > 40), 'Valid Day'] = 'yes'\n",
    "\n",
    "# df_steps_missing_Lockdown_all_years_copy = df_steps_missing\n",
    "\n",
    "# restrict time\n",
    "df_all_periods = df_steps_missing[(df_steps_missing['Start_Time_Date_Offset_x'] > dt.date(2019, 3, 1)) & (df_steps_missing['Start_Time_Date_Offset_x'] < dt.date(2021, 6, 30))]\n",
    "\n",
    "print(df_all_periods['Start_Time_Date_Offset_x'].min())\n",
    "print(df_all_periods['Start_Time_Date_Offset_x'].max())\n",
    "\n",
    "df_all_periods.loc[(df_all_periods['Start_Time_Date_Offset_x'] < dt.date(2020, 3, 15)) & (df_all_periods['Start_Time_Date_Offset_x'] > dt.date(2019, 3, 1)), 'closure_status'] = 'Pre Closure'\n",
    "df_all_periods.loc[(df_all_periods['Start_Time_Date_Offset_x'] < dt.date(2021, 3, 31)) & (df_all_periods['Start_Time_Date_Offset_x'] > dt.date(2020, 3, 15)), 'closure_status'] = 'During Closure'\n",
    "df_all_periods.loc[(df_all_periods['Start_Time_Date_Offset_x'] > dt.date(2021, 3, 31)), 'closure_status'] = 'Post Closure'\n",
    "\n",
    "print(df_all_periods.groupby('closure_status')['Start_Time_Date_Offset_x'].min())\n",
    "print(df_all_periods.groupby('closure_status')['Start_Time_Date_Offset_x'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_days = df_all_periods[df_all_periods['Valid Day'] == 'yes']\n",
    "\n",
    "df_valid_days['Num_of_days_valid_epochs'] = df_valid_days.groupby(['User UUID'])['Start_Time_Date_Offset_x'].transform('nunique')\n",
    "\n",
    "df_valid_days_daycount = df_valid_days[df_valid_days['Num_of_days_valid_epochs'] > 60]\n",
    "\n",
    "df_valid_days_daycount['Epochs_per_day'].min()\n",
    "df_valid_days_daycount['Epochs_per_day'].max()\n",
    "\n",
    "epoch_count = df_all_periods\n",
    "epoch_count['Num_of_days_valid_epochs'] = epoch_count.groupby(['User UUID'])['Start_Time_Date_Offset_x'].transform('nunique')\n",
    "\n",
    "epoch_count = df_all_periods.drop_duplicates(subset=['User UUID', 'Num_of_days_valid_epochs'], keep='first')\n",
    "\n",
    "\n",
    "print(range(len(epoch_count_only)))\n",
    "print(194/2)\n",
    "\n",
    "epoch_count_only.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(100,40))\n",
    "plt.figure(figsize=(60,20))\n",
    "sns.set(font_scale=5)\n",
    "default_x_ticks = range(len(epoch_count_only))\n",
    "fig, ax = plt.subplots(figsize=(60,20))\n",
    "ax.hist(epoch_count_only['Num_of_days_valid_epochs'], bins=61, cumulative=-1, density=False)\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 120]['User UUID'].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 61].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 40].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 70].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 80].nunique()\n",
    "\n",
    "epoch_count_only[epoch_count_only['Num_of_days_valid_epochs'] > 90].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "df_epoch_dup = df_all_periods.drop_duplicates(subset=['User UUID', 'Start_Time_Date_Offset_x'], keep='last', inplace=False)\n",
    "df2 = df_epoch_dup.groupby(['User UUID', 'Epochs_per_day'])['Start_Time_Date_Offset_x'].count()\n",
    "\n",
    "df3 = df2.reset_index()\n",
    "\n",
    "df3['Epochs_per_day'] = df3['Epochs_per_day'].replace(np.nan, 0)\n",
    "df3['Start_Time_Date_Offset_x'] = df3['Start_Time_Date_Offset_x'].replace(np.nan, 0)\n",
    "\n",
    "df_pivot = df3.pivot_table(values='User UUID', index=['Epochs_per_day'], columns=['Start_Time_Date_Offset_x'], aggfunc=pd.Series.nunique)\n",
    "df_pivot.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20, 7)})\n",
    "sns.set_context(\"paper\", rc={\"font.size\":90,\"axes.titlesize\":50,\"axes.labelsize\":20})\n",
    "sns.set(rc={\"axes.facecolor\":\"snow\", \"figure.facecolor\":\"white\"})\n",
    "ax = sns.heatmap(df_pivot, cmap=\"rocket_r\", mask=(df_pivot==0))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "df_valid_days_daycount['User UUID'].nunique()\n",
    "\n",
    "df_valid_days_daycount['Total_Steps_Per_Day_post_missing'] = df_valid_days_daycount.groupby(['Start_Time_Date_Offset_x', 'User UUID'])['Total_Steps_Per_Day'].transform('sum')\n",
    "\n",
    "df_valid_days_daycount['Average_Monthly_Steps_Lockdown_post_missing'] = df_valid_days_daycount.groupby(['User UUID', 'Month_Year_Name'])['Total_Steps_Per_Day_post_missing'].transform('mean')\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_days_daycount_dup = df_valid_days_daycount.drop_duplicates(subset=['User UUID', 'Average_Monthly_Steps_Lockdown_post_missing', 'Month_Year_Name'], keep='first')\n",
    "df_valid_days_daycount_dup\n",
    "\n",
    "# Min\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].min()\n",
    "\n",
    "# Max\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].max()\n",
    "\n",
    "# Mean\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].mean()\n",
    "\n",
    "# Std\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['Average_Monthly_Steps_Lockdown_post_missing'].std()\n",
    "\n",
    "# Users\n",
    "df_valid_days_daycount_dup.groupby('closure_status')['User UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_days_daycount_dup_month = df_valid_days_daycount_dup\n",
    "df_valid_days_daycount_dup_month['average_steps_per_month_post_missing'] = df_valid_days_daycount_dup_month.groupby(['Month_Year_Name'])['Average_Monthly_Steps_Lockdown_post_missing'].transform('mean')\n",
    "df_valid_days_daycount_dup_month = df_valid_days_daycount_dup_month.drop_duplicates(subset=['average_steps_per_month_post_missing', 'Month_Year_Name'], keep='first')\n",
    "df_valid_days_daycount_dup_month\n",
    "\n",
    "df_valid_days_daycount_dup_month['Month_Year_Name'].unique()\n",
    "\n",
    "# Min\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].min()\n",
    "\n",
    "# Max\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].max()\n",
    "\n",
    "# Mean\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].mean()\n",
    "\n",
    "# Std\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['average_steps_per_month_post_missing'].std()\n",
    "\n",
    "# Users\n",
    "df_valid_days_daycount_dup_month.groupby('closure_status')['User UUID'].nunique()\n",
    "\n",
    "# Exclude summer for TOD comparison with overall\n",
    "df_valid_days_daycount_dup_month_non_sum = df_valid_days_daycount_dup_month[(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jun-2020') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jul-2020') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Aug-2020') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jun-2019') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jul-2019') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Aug-2019') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jun-2021') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Jul-2021') & \n",
    "(df_valid_days_daycount_dup_month['Month_Year_Name'] != 'Aug-2021')]\n",
    "df_valid_days_daycount_dup_month_non_sum\n",
    "\n",
    "# Mean\n",
    "df_valid_days_daycount_dup_month_non_sum.groupby('closure_status')['average_steps_per_month_post_missing'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "# df_steps_missing_Lockdown_all_years_valid_days_daycount_fig4['year_only'] = df_steps_missing_Lockdown_all_years_valid_days_daycount\n",
    "\n",
    "df_valid_days_daycount_dup_fig = df_valid_days_daycount_dup\n",
    "df_valid_days_daycount_dup_fig['pre_avg'] = 8809.83\n",
    "\n",
    "plt.figure(figsize=(60, 20))\n",
    "sns.set(font_scale=5)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"Set1\", 8, .75)\n",
    "ax = sns.lineplot(x='Month_Year_Name', y='Average_Monthly_Steps_Lockdown_post_missing', \n",
    "                  data=df_valid_days_daycount_dup_fig, color='darkcyan', \n",
    "                  linewidth=15, sort=False)\n",
    "sns.lineplot(x='Month_Year_Name', y='pre_avg', \n",
    "             data=df_valid_days_daycount_dup_fig, color='grey', \n",
    "             linestyle='--', linewidth=10, sort=False)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel(\"Month\", fontdict={'fontsize': 60, 'fontweight': 'bold'}, labelpad=-2)\n",
    "ax.set_ylabel(\"Average Daily Number of Steps Per Month\", fontdict={'fontsize': 55, 'fontweight': 'bold'})\n",
    "ax.set_title(\"Average Daily Step Values for Participants (Non zero MMI, after missingness analysis)\", fontdict={'fontsize': 60, 'fontweight': 'bold'})\n",
    "ax.axvline(\"1-14 Mar-2020\", color=\"firebrick\", linestyle=\"--\", lw=10)\n",
    "ax.legend(loc=\"upper right\", frameon=True, fontsize=50)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='50') # for Legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='50') # for Legend title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "steps_pre_closure = df_valid_days_daycount_dup[df_valid_days_daycount_dup['closure_status'] == 'Pre Closure']\n",
    "\n",
    "steps_pre_closure['Monthly_Avg'] = steps_pre_closure.groupby(['Month_Year_Name'])['Average_Monthly_Steps_Lockdown_post_missing'].transform('mean')\n",
    "\n",
    "steps_pre_closure['month_num'] = steps_pre_closure['Start_Time_Offset'].dt.month\n",
    "# steps_pre['month_num'].unique()\n",
    "steps_pre_closure = steps_pre_closure.sort_values(by=['month_num'])\n",
    "# steps_pre_closure\n",
    "\n",
    "steps_pre_closure_col = steps_pre_closure[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_pre_closure_dup = steps_pre_closure_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "# steps_pre_closure_dup\n",
    "\n",
    "steps_dur_closure = df_valid_days_daycount_dup[df_valid_days_daycount_dup['closure_status'] == 'During Closure']\n",
    "\n",
    "steps_dur_closure['Monthly_Avg'] = steps_dur_closure.groupby(['Month_Year_Name'])['Average_Monthly_Steps_Lockdown_post_missing'].transform('mean')\n",
    "\n",
    "steps_dur_closure['month_num'] = steps_dur_closure['Start_Time_Offset'].dt.month\n",
    "# steps_pre['month_num'].unique()\n",
    "steps_dur_closure = steps_dur_closure.sort_values(by=['month_num'])\n",
    "# steps_dur_closure\n",
    "\n",
    "steps_dur_closure_col = steps_dur_closure[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_dur_closure_dup = steps_dur_closure_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "# steps_dur_closure_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "U1, p = mannwhitneyu(steps_dur_closure_dup['Monthly_Avg'], steps_pre_closure_dup['Monthly_Avg'])\n",
    "print(U1)\n",
    "print(p)\n",
    "print(p * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time of day analysis\n",
    "df_closure_tod = df_valid_days_daycount\n",
    "\n",
    "df_closure_tod['Start Time Only Time'] = df_closure_tod['Start_Time_Offset'].dt.strftime(\"%H:%M:%S\")\n",
    "# all_data_merged_steps[all_data_merged_steps['Start Time Only Time'] > '16:15:00']\n",
    "# base on data instead\n",
    "df_closure_tod['Time_Of_Day'] = \"Night\"\n",
    "df_closure_tod.loc[df_closure_tod['Start Time Only Time'] < '11:00:00', 'Time_Of_Day'] = 'Morning'\n",
    "df_closure_tod.loc[(df_closure_tod['Start Time Only Time'] >= '07:00:00') &\n",
    "                   (df_closure_tod['Start Time Only Time'] < '16:00:00'), 'Time_Of_Day'] = 'Afternoon'\n",
    "df_closure_tod.loc[(df_closure_tod['Start Time Only Time'] >= '11:00:00') &\n",
    "                   (df_closure_tod['Start Time Only Time'] < '20:00:00'), 'Time_Of_Day'] = 'Evening'\n",
    "\n",
    "# aft = df_steps_missing_all_dates_copy_fig3[df_steps_missing_all_dates_copy_fig3['Time_Of_Day'] == 'Evening']\n",
    "# aft['Start Time Only Time'].unique()\n",
    "\n",
    "df_closure_tod['wkday_Num'] = df_closure_tod['Start_Time_Offset'].dt.weekday\n",
    "df_closure_tod['wkday_Num'].unique()\n",
    "\n",
    "df_closure_tod_wkday = df_closure_tod[df_closure_tod['wkday_Num'].isin([0,1,2,3,4])]\n",
    "df_closure_tod_wkday['wkday_Num'].unique()\n",
    "\n",
    "df_closure_tod_wkday[['wkday_Num', 'Start_Time_Offset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_closure_tod_wkday_school = df_closure_tod_wkday[df_closure_tod_wkday['Time_Of_Day'].isin(['Morning', 'Afternoon'])]\n",
    "df_closure_tod_wkday_school_non_sum = df_closure_tod_wkday_school[~df_closure_tod_wkday_school['Mon_Year'].isin(['Jun-2020', 'Jul-2020', 'Aug-2020', 'Jun-2019', 'Jul-2019', 'Aug-2019', 'Jun-2021', 'Jul-2021', 'Aug-2021'])]\n",
    "df_closure_tod_wkday_school_non_sum['Daily_Sum_TOD'] = df_closure_tod_wkday_school_non_sum.groupby(['Start_Time_Date_Offset_x', 'User_UUID'])['Steps'].transform('sum')\n",
    "df_closure_tod_wkday_school_non_sum['mean_monthly_steps_school'] = df_closure_tod_wkday_school_non_sum.groupby(['User_UUID', 'Month_Year_Name'])['Daily_Sum_TOD'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_non_sum_dup = df_closure_tod_wkday_school_non_sum.drop_duplicates(subset=['User_UUID', 'mean_monthly_steps_school'])\n",
    "df_closure_tod_wkday_school_non_sum_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['mean_monthly_steps_school'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['mean_monthly_steps_school'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['mean_monthly_steps_school'].std()\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_non_sum_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_fig = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] != 'Post Closure']\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\n",
    "    \"Pre Closure\": \"mediumpurple\",\n",
    "    \"During Closure\": \"lightcoral\"\n",
    "#     \"#2020\": \"salmon\"\n",
    "}\n",
    "\n",
    "ax = sns.boxplot(x=\"Month_Year_Name\", y=\"mean_monthly_steps_school\", palette=palette, hue=\"closure_status\",\n",
    "                 data=df_closure_tod_fig, linewidth=14,\n",
    "                 showfliers=False, dodge=False, width=0.5,\n",
    "                 showmeans=True)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "# ax.set_title('Average Step Values for Participants Before and After Lockdown For School Times')\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times',\n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_fig = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] != 'Post Closure']\n",
    "fig_2_df_closure_tod = df_closure_tod_fig\n",
    "# Following lines are not completely visible in the image, but here's the visible part:\n",
    "fig_2_df_closure_tod['Month Year Name_Closure'] = fig_2_df_closure_tod['Month Year Name'].str[0:3]\n",
    "fig_2_df_closure_tod.loc[(fig_2_df_closure_tod['Month Year Name_Closure'] == 'Mar'), 'Month Year Name_Closure'] = 'Mar-2020'\n",
    "fig_2_df_closure_tod.loc[(fig_2_df_closure_tod['Month Year Name_Closure'] == 'Mar'), 'Month Year Name_Closure'] = 'Mar-'\n",
    "fig_2_df_closure_tod['month only'] = pd.Categorical(fig_2_df_closure_tod['Month Year Name_Closure'],\n",
    "                                                    categories=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Sep', 'Oct', 'Nov', 'Dec'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out line\n",
    "# df_closure_tod_fig=df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status']=='Post Closure']\n",
    "\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\"Pre Closure\": \"mediumpurple\",\n",
    "           \"During Closure\": \"lightcoral\",\n",
    "           \"#2020\": \"salmon\"}\n",
    "\n",
    "ax = sns.boxplot(x=\"month_only\", y=\"mean_monthly_steps_school\", palette=palette, hue=\"closure_status\",\n",
    "                 data=fig_2_df_closure_tod, linewidth=14, showfliers=False, dodge=False, width=0.5, showmeans=True)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times', \n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one value per month\n",
    "df_closure_tod_wkday_school_non_sum_dup_month = df_closure_tod_wkday_school_non_sum_dup\n",
    "df_closure_tod_wkday_school_non_sum_dup_month['mean_monthly_steps_school_per_month'] = df_closure_tod_wkday_school_non_sum_dup_month.groupby(['Month_Year_Name'])['mean_monthly_steps_school'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup = df_closure_tod_wkday_school_non_sum_dup_month.drop_duplicates(subset=['mean_monthly_steps_school_per_month', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "# Min\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].min()\n",
    "\n",
    "# Max\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_per_month'].std()\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_non_sum_dup_month_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "steps_pre_closure_wkday_school_non_sum = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] == 'Pre Closure']\n",
    "steps_pre_closure_wkday_school_non_sum['Monthly_Avg'] = steps_pre_closure_wkday_school_non_sum.groupby(['Month_Year_Name'])['mean_monthly_steps_school'].transform('mean')\n",
    "steps_pre_closure_wkday_school_non_sum['month_num'] = steps_pre_closure_wkday_school_non_sum['Start_Time_Offset'].dt.month\n",
    "steps_pre_closure_wkday_school_non_sum = steps_pre_closure_wkday_school_non_sum.sort_values(by=['month_num'])\n",
    "steps_pre_closure_wkday_school_non_sum_col = steps_pre_closure_wkday_school_non_sum[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_pre_closure_wkday_school_non_sum_col_dup = steps_pre_closure_wkday_school_non_sum_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "steps_dur_closure_wkday_school_non_sum = df_closure_tod_wkday_school_non_sum_dup[df_closure_tod_wkday_school_non_sum_dup['closure_status'] == 'During Closure']\n",
    "steps_dur_closure_wkday_school_non_sum['Monthly_Avg'] = steps_dur_closure_wkday_school_non_sum.groupby(['Month_Year_Name'])['mean_monthly_steps_school'].transform('mean')\n",
    "steps_dur_closure_wkday_school_non_sum['month_num'] = steps_dur_closure_wkday_school_non_sum['Start_Time_Offset'].dt.month\n",
    "steps_dur_closure_wkday_school_non_sum = steps_dur_closure_wkday_school_non_sum.sort_values(by=['month_num'])\n",
    "steps_dur_closure_wkday_school_non_sum_col = steps_dur_closure_wkday_school_non_sum[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_dur_closure_wkday_school_non_sum_col_dup = steps_dur_closure_wkday_school_non_sum_col.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "U1, p = mannwhitneyu(steps_dur_closure_wkday_school_non_sum_col_dup['Monthly_Avg'], steps_pre_closure_wkday_school_non_sum_col_dup['Monthly_Avg'])\n",
    "print(U1)\n",
    "print(p*100)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer months weekday steps analysis (pre-, during-, and post-closure)\n",
    "\n",
    "# Starting dataset used: df_closure_tod_wkday_school\n",
    "df_closure_tod_wkday_school_only_sum = df_closure_tod_wkday_school[\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jun-2020') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jul-2020') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Aug-2020') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jun-2019') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jul-2019') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Aug-2019') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jun-2021') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Jul-2021') |\n",
    "    (df_closure_tod_wkday_school['Mon_Year'] == 'Aug-2021')\n",
    "]\n",
    "\n",
    "df_closure_tod_wkday_school_only_sum['Daily_Sum_TOD'] = df_closure_tod_wkday_school_only_sum.groupby(['Start_Time_Date_Offset_x'])['Steps'].transform('sum')\n",
    "df_closure_tod_wkday_school_only_sum['mean_monthly_steps_school_sum'] = df_closure_tod_wkday_school_only_sum.groupby(['User_UUID'])['Daily_Sum_TOD'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_only_sum_dup = df_closure_tod_wkday_school_only_sum.drop_duplicates(subset=['User_UUID', 'mean_monthly_steps_school_sum'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].min()\n",
    "\n",
    "# Max\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['mean_monthly_steps_school_sum'].std()\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_only_sum_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_wkday_school_only_sum_dup_fig = df_closure_tod_wkday_school_only_sum_dup[df_closure_tod_wkday_school_only_sum_dup['closure_status'] != 'Post Closure']\n",
    "\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\"Pre Closure\": \"yellowgreen\",\n",
    "           \"During Closure\": \"lightsalmon\"\n",
    "#            \"#2020\": \"salmon\"\n",
    "          }\n",
    "\n",
    "ax = sns.boxplot(x=\"month_only\", y=\"mean_monthly_steps_school_sum\", palette=palette, hue='closure_status',\n",
    "                 data=fig_3_df_closure_tod, linewidth=14, showfliers=False,\n",
    "                 showmeans=False, width=0.5)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times',\n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closure_tod_wkday_school_only_sum_dup_fig = df_closure_tod_wkday_school_only_sum_dup[\n",
    "    df_closure_tod_wkday_school_only_sum_dup['closure_status'] != 'Post Closure']\n",
    "\n",
    "plt.figure(figsize=(100, 40))\n",
    "sns.set_style(\"white\")\n",
    "palette = {\n",
    "    \"Pre Closure\": \"yellowgreen\",\n",
    "    \"During Closure\": \"lightsalmon\"\n",
    "#     \"#2020\": \"salmon\"\n",
    "}\n",
    "\n",
    "ax = sns.boxplot(x=\"month_only\", y=\"mean_monthly_steps_school_sum\", palette=palette, hue=\"closure_status\",\n",
    "                 data=fig_3_df_closure_tod, linewidth=14, showfliers=False,\n",
    "                 showmeans=False, width=0.5)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_xlabel('Month', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_ylabel('Number of Steps', fontdict={'fontsize': 90, 'fontweight': 'bold'})\n",
    "ax.set_title('Average Daily Step Count Values for Participants Before and After Lockdown During School Times',\n",
    "             fontdict={'fontsize': 90, 'fontweight': 'bold'}, y=1.05)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, frameon=True, edgecolor='black',\n",
    "           title=\"Pandemic Status\", framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one value per month\n",
    "df_closure_tod_wkday_school_only_sum_dup_month = df_closure_tod_wkday_school_only_sum_dup\n",
    "df_closure_tod_wkday_school_only_sum_dup_month['mean_monthly_steps_school_sum_per_month'] = df_closure_tod_wkday_school_only_sum_dup_month.groupby(['Month_Year_Name'])['mean_monthly_steps_school_sum'].transform('mean')\n",
    "\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup = df_closure_tod_wkday_school_only_sum_dup_month.drop_duplicates(subset=['mean_monthly_steps_school_sum_per_month', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "# Min\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].min()\n",
    "\n",
    "# Max\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].max()\n",
    "\n",
    "# Mean\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].mean()\n",
    "\n",
    "# Std\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['mean_monthly_steps_school_sum_per_month'].std()\n",
    "\n",
    "\n",
    "# Users\n",
    "df_closure_tod_wkday_school_only_sum_dup_month_dup.groupby('closure_status')['User_UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "steps_pre_closure_wkday_school_only_sum_dup = df_closure_tod_wkday_school_only_sum_dup[df_closure_tod_wkday_school_only_sum_dup['closure_status'] == 'Pre Closure']\n",
    "steps_pre_closure_wkday_school_only_sum_dup['Monthly_Avg'] = steps_pre_closure_wkday_school_only_sum_dup.groupby(['Month_Year_Name'])['mean_monthly_steps_school_sum'].transform('mean')\n",
    "steps_pre_closure_wkday_school_only_sum_dup['month_num'] = steps_pre_closure_wkday_school_only_sum_dup['Start_Time_Offset'].dt.month\n",
    "steps_pre_closure_wkday_school_only_sum_dup = steps_pre_closure_wkday_school_only_sum_dup.sort_values(by=['month_num'])\n",
    "steps_pre_closure_wkday_school_only_sum_col_dup = steps_pre_closure_wkday_school_only_sum_dup[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_pre_closure_wkday_school_only_sum_col_dup = steps_pre_closure_wkday_school_only_sum_col_dup.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "\n",
    "steps_dur_closure_wkday_school_only_sum_dup = df_closure_tod_wkday_school_only_sum_dup[df_closure_tod_wkday_school_only_sum_dup['closure_status'] == 'During Closure']\n",
    "steps_dur_closure_wkday_school_only_sum_dup['Monthly_Avg'] = steps_dur_closure_wkday_school_only_sum_dup.groupby(['Month_Year_Name'])['mean_monthly_steps_school_sum'].transform('mean')\n",
    "steps_dur_closure_wkday_school_only_sum_dup['month_num'] = steps_dur_closure_wkday_school_only_sum_dup['Start_Time_Offset'].dt.month\n",
    "steps_dur_closure_wkday_school_only_sum_dup = steps_dur_closure_wkday_school_only_sum_dup.sort_values(by=['month_num'])\n",
    "steps_dur_closure_wkday_school_only_sum_col_dup = steps_dur_closure_wkday_school_only_sum_dup[['Month_Year_Name', 'Monthly_Avg']]\n",
    "steps_dur_closure_wkday_school_only_sum_col_dup = steps_dur_closure_wkday_school_only_sum_col_dup.drop_duplicates(subset=['Monthly_Avg', 'Month_Year_Name'], keep='first')\n",
    "steps_dur_closure_wkday_school_only_sum_col_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "U1, p = mannwhitneyu(steps_dur_closure_wkday_school_only_sum_col_dup['Monthly_Avg'],\n",
    "                     steps_pre_closure_wkday_school_only_sum_col_dup['Monthly_Avg'])\n",
    "print(U1)\n",
    "print(p*100)\n",
    "print(p)\n",
    "\n",
    "# Sleep\n",
    "df_sleep = df[df['Type'] == 'sleepDuration']\n",
    "len(df_sleep)\n",
    "\n",
    "df_sleep['User UUID'].nunique()\n",
    "\n",
    "steps_user_id_list = df_valid_days_daycount['User UUID'].nunique()\n",
    "\n",
    "df_sleep_step_ids = df_sleep[df_sleep['User UUID'].isin(steps_user_id_list)]\n",
    "df_sleep_step_ids\n",
    "\n",
    "df_sleep_step_ids['User UUID'].nunique()\n",
    "\n",
    "df_valid_days_daycount['User UUID'].nunique()\n",
    "\n",
    "df_valid_days_daycount['User UUID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_step_ids['Start Time'] = df_sleep_step_ids['Start Time'].apply(pd.to_datetime)\n",
    "df_sleep_step_ids['End Time'] = df_sleep_step_ids['End Time'].apply(pd.to_datetime)\n",
    "\n",
    "df_sleep_step_ids['Start Time Offset'] = df_sleep_step_ids['Start Time'] + pd.to_timedelta(df_sleep_step_ids['Time Zone Offset'], unit='m')\n",
    "df_sleep_step_ids['End Time Offset'] = df_sleep_step_ids['End Time'] + pd.to_timedelta(df_sleep_step_ids['Time Zone Offset'], unit='m')\n",
    "\n",
    "df_sleep_step_ids['Start Time Date Offset'] = df_sleep_step_ids['Start Time Offset'].dt.date\n",
    "df_sleep_step_ids['End Time Date Offset'] = df_sleep_step_ids['End Time Offset'].dt.date\n",
    "df_sleep_step_ids['month_year'] = df_sleep_step_ids['Start Time Offset'].dt.to_period('M')\n",
    "\n",
    "df_sleep_step_ids['Mon Year'] = df_sleep_step_ids['Start Time Offset'].dt.strftime('%b-%Y')\n",
    "df_sleep_step_ids['Month Year Name'] = df_sleep_step_ids['Mon Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_copy = df_sleep_step_ids\n",
    "df_sleep_copy_dup = df_sleep_copy.drop_duplicates(subset=['User UUID', 'Start Time', 'End Time', 'Value'], keep='first')\n",
    "df_sleep_copy_dup\n",
    "\n",
    "df_sleep_copy_dup['User UUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_copy_dup['year_only'] = df_sleep_copy_dup['Start Time Offset'].dt.year\n",
    "df_sleep_copy_dup['month_only'] = df_sleep_copy_dup['Start Time Offset'].dt.strftime(\"%B\")\n",
    "df_sleep_copy_dup['Start Time Only Time'] = df_sleep_copy_dup['Start Time Offset'].dt.strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Convert to datetime format to calculate bedtime date\n",
    "df_sleep_copy_dup['Start Time Only Time Datetime'] = df_sleep_copy_dup['Start Time Only Time'].apply(pd.to_datetime)\n",
    "\n",
    "# Get only nighttime values\n",
    "# diff=445416-410584\n",
    "# change based on today's date\n",
    "df_sleep_bedtime_calc_allnight = df_sleep_copy_dup[(df_sleep_copy_dup['Start Time Only Time Datetime'] > dt.datetime(2023, 6, 27, 18, 0, 0)) &\n",
    "                                                   (df_sleep_copy_dup['Start Time Only Time Datetime'] < dt.datetime(2023, 6, 27, 8, 0, 0))]\n",
    "\n",
    "df_sleep_bedtime_calc_allnight['Start Time Only Time Datetime'].dt.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why twice?\n",
    "df_sleep_bedtime_calc_allnight['Start Time Only Time Datetime'] = df_sleep_bedtime_calc_allnight['Start Time Only Time'].apply(pd.to_datetime)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val = df_sleep_bedtime_calc_allnight\n",
    "# change according to today's date\n",
    "df_sleep_bedtime_calc_allnight_val.loc[(df_sleep_bedtime_calc_allnight_val['Start Time Only Time Datetime'] \n",
    "                                        > dt.datetime(2023, 6, 27, 18, 0, 0)), 'Bedtime_Date'] = \n",
    "df_sleep_bedtime_calc_allnight_val['Start Time_Date_Offset']\n",
    "df_sleep_bedtime_calc_allnight_val.loc[(df_sleep_bedtime_calc_allnight_val['Start Time Only Time Datetime'] \n",
    "                                        < dt.datetime(2023, 6, 27, 18, 0, 0)), 'Bedtime_Date'] = \n",
    "df_sleep_bedtime_calc_allnight_val['Start_Time_Date_Offset'] - timedelta(days=1)\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Start Time_Offset_dt'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['Start Time_Offset'])\n",
    "df_sleep_bedtime_calc_allnight_val['End Time_Offset_dt'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['End Time_Offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_bedtime_calc_allnight_val['Start_Time_Offset_dt'] = df_sleep_bedtime_calc_allnight_val['Start_Time_Offset_dt'].astype('int64') // 1e9\n",
    "df_sleep_bedtime_calc_allnight_val['End_Time_Offset_dt'] = df_sleep_bedtime_calc_allnight_val['End_Time_Offset_dt'].astype('int64') // 1e9\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso'] = df_sleep_bedtime_calc_allnight_val.groupby(['User UUID', 'Bedtime_Date'])['Start_Time_Offset_dt_iso'].transform('min')\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso'] = df_sleep_bedtime_calc_allnight_val.groupby(['User UUID', 'Bedtime_Date'])['End_Time_Offset_dt_iso'].transform('max')\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso'], unit='s')\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso'], unit='s')\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted_dt'] = df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted'].apply(pd.to_datetime)\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted_dt'] = df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted'].apply(pd.to_datetime)\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val['Bedtime_Min_iso_int_converted_dt'].strftime(\"%H:%M:%S\")\n",
    "df_sleep_bedtime_calc_allnight_val['Waketime_Max_iso_int_converted_dt'].strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import rect, phase\n",
    "from math import radians, degrees\n",
    "\n",
    "def meanAngle(deg):\n",
    "    complexDegree = sum(rect(1, radians(d)) for d in deg) / len(deg)\n",
    "    argument = phase(complexDegree)\n",
    "    meanAngle = degrees(argument)\n",
    "    return meanAngle\n",
    "\n",
    "def meanTime(times):\n",
    "    t = (time.split(':') for time in times)\n",
    "    seconds = sum((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n",
    "    \n",
    "    day = 24 * 60 * 60\n",
    "    toAngles = [s * 360. / day for s in seconds]\n",
    "    meanAsAngle = meanAngle(toAngles)\n",
    "    meanSeconds = meanAsAngle * day / 360.\n",
    "    \n",
    "    if meanSeconds < 0:\n",
    "        meanSeconds += day\n",
    "    h, m = divmod(meanSeconds, 3600)\n",
    "    m, s = divmod(m, 60)\n",
    "    \n",
    "    return '%02i:%02i:%02i' % (h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sleep_bedtime_calc_allnight_val_copy = df_sleep_bedtime_calc_allnight_val\n",
    "\n",
    "# get month from bedtime\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date_month_year'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date']).dt.to_period('M')\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date_month_year_abb'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date']).dt.strftime('%b')\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date_month_year']\n",
    "\n",
    "# Do we need this?\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Mon_Year_Bedtime'] = pd.to_datetime(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date']).dt.strftime('%b-%Y')\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Month_Year_Name_Bedtime'] = df_sleep_bedtime_calc_allnight_val_copy['Mon_Year_Bedtime']\n",
    "\n",
    "df_sleep_bedtime_calc_allnight_val_copy['Month_Year_Name_Bedtime'] = df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date\n",
    "df_sleep_bedtime_calc_allnight_val_copy.loc[(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date < dt.date(2020, 3, 15)) &\n",
    "                                            (df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date >= dt.date(2020, 3, 1)),\n",
    "                                            'Month_Year_Name_Bedtime'] = '1-14 Mar-2020'\n",
    "df_sleep_bedtime_calc_allnight_val_copy.loc[(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date < dt.date(2020, 4, 1)) &\n",
    "                                            (df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date >= dt.date(2020, 3, 15)),\n",
    "                                            'Month_Year_Name_Bedtime'] = '15-31 Mar-2020'\n",
    "df_sleep_bedtime_calc_allnight_val_copy.loc[(df_sleep_bedtime_calc_allnight_val_copy['Bedtime_Date'].dt.date < dt.date(2020, 4, 1)),\n",
    "                                            'Month_Year_Name_Bedtime'] = df_sleep_bedtime_calc_allnight_val_copy.Month_Year_Name_Bedtime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
